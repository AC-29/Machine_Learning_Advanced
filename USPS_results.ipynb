{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USPS_results replication\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "from tsvm import TSVM\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "with open ('usbs_databases', 'rb') as fp:\n",
    "    usps_file = pickle.load(fp) \n",
    "\n",
    "partition = usps_file[0]\n",
    "df_usps_sample = usps_file[1]\n",
    "df_usps_test = usps_file[2]\n",
    "\n",
    "def get_mean_and_std(partition,gram='0',method='svm'):\n",
    "    sigma=6\n",
    "    accuracy = np.zeros(50)\n",
    "    gam = 1/(2*sigma**2)\n",
    "    if(method=='cluster_kernel'): #cluster kernel\n",
    "        trn = df_usps_sample.iloc[:,1:].to_numpy()\n",
    "        tes = df_usps_test.iloc[:,1:].to_numpy()\n",
    "        data = np.concatenate((trn,tes),axis=0)\n",
    "        print('data dimensions', data.shape)\n",
    "        lin_ker = extension_cluster_kernel(data,'linear')\n",
    "        eig = lin_ker.eigvalues\n",
    "        print('eig:',eig)\n",
    "        print('eig length:',eig.shape)\n",
    "        cut_off = k_th_largest_eig(eig,15)\n",
    "        print('cut_off:',cut_off)\n",
    "        lin_ker.poly_step([cut_off,1/2,1])\n",
    "        for i in range(50):\n",
    "            #for each i, use partition[i] as train, and the rest as test\n",
    "            data_partition = partition[i].iloc[:,1:]\n",
    "            targets = partition[i].iloc[:,0].to_numpy()\n",
    "            inputs =  data_partition.to_numpy()\n",
    "            unlabeled_df = df_usps_sample.drop(partition[i].index) #'drop' simply ingores the indeces from particion [i], giving us the 'rest'\n",
    "            unlabeled_targets=unlabeled_df.iloc[:,0].to_numpy()\n",
    "            unlabeled_inputs =unlabeled_df.iloc[:,1:].to_numpy()\n",
    "            test_df = df_usps_test\n",
    "            test_inputs = test_df.iloc[:,1:].to_numpy()\n",
    "            test_targets= test_df.iloc[:,0].to_numpy()\n",
    "            clf = svm.SVC(kernel=lin_ker.distance, C=100,class_weight='balanced')\n",
    "            print('number of +1:',targets[targets==1].shape)\n",
    "            print('number of -1:',targets[targets==-1].shape)\n",
    "            clf.fit(inputs,targets)\n",
    "            accuracy[i] = clf.score(test_inputs,test_targets)\n",
    "            print('accuracy at iteration'+str(i)+':',accuracy[i]) \n",
    "        print(accuracy)\n",
    "        print('mean:', np.mean(accuracy))\n",
    "        print('std:', np.std(accuracy))\n",
    "    elif(method=='svm'): #svm\n",
    "        for i in range(50):\n",
    "            #for each i, use partition[i] as train, and the rest as test\n",
    "            data_partition = partition[i].iloc[:,1:]\n",
    "            targets = partition[i].iloc[:,0].to_numpy()\n",
    "            #data_partition = df_usps_sample.iloc[:,1:]\n",
    "            #targets = df_usps_sample.iloc[:,0].to_numpy()\n",
    "            inputs =  data_partition.to_numpy()\n",
    "            test_df = df_usps_test\n",
    "            test_targets=test_df.iloc[:,0].to_numpy()\n",
    "            test_inputs =test_df.iloc[:,1:].to_numpy()\n",
    "            #print(inputs_scaled.std(axis=0))\n",
    "            #pca = PCA(n_components = 0.95, svd_solver='full')\n",
    "            #pca.fit(inputs)\n",
    "            #transformed_inputs = pca.transform(inputs)\n",
    "            #transformed_test_inputs = pca.transform(test_inputs)\n",
    "            clf = svm.SVC(kernel='rbf', C=100,gamma=gam,class_weight='balanced')\n",
    "            clf.fit(inputs, targets)\n",
    "            accuracy[i] = clf.score(test_inputs,test_targets)\n",
    "            print('accuracy at iteration'+str(i)+':',accuracy[i])\n",
    "        print('sigma:', sigma)\n",
    "        print(accuracy)\n",
    "        print('mean:', np.mean(accuracy))\n",
    "        print('std:', np.std(accuracy))\n",
    "    else:#tsvm\n",
    "\n",
    "        for i in range(50):\n",
    "            #for each i, use partition[i] as train, and the rest as test\n",
    "            data_partition = partition[i].iloc[:,1:]\n",
    "            targets = partition[i].iloc[:,0].to_numpy()\n",
    "            inputs =  data_partition.to_numpy()\n",
    "            unlabeled_df = df_usps_sample.drop(partition[i].index) #'drop' simply ingores the indeces from particion [i], giving us the 'rest'\n",
    "            unlabeled_targets=unlabeled_df.iloc[:,0].to_numpy()\n",
    "            unlabeled_inputs =unlabeled_df.iloc[:,1:].to_numpy()\n",
    "            test_df = df_usps_test\n",
    "            test_inputs = test_df.iloc[:,1:].to_numpy()\n",
    "            test_targets= test_df.iloc[:,0].to_numpy()\n",
    "            clf = TSVM()\n",
    "            gamma = gam \n",
    "            C = 10\n",
    "            clf.initial('rbf',gam,C)\n",
    "            print(targets)\n",
    "            clf.train(inputs,targets,unlabeled_inputs)\n",
    "            test_predict = clf.predict(test_inputs)\n",
    "            accuracy[i] = test_predict[test_predict==test_targets].size/test_predict.size\n",
    "            print(accuracy[i])\n",
    "            #clf = svm.SVC(kernel='rbf', C=10,gamma=gam,class_weight='balanced')\n",
    "            #clf.fit(inputs, targets)\n",
    "            #accuracy[i] = clf.score(test_inputs,test_targets)\n",
    "        print(accuracy)\n",
    "        print('mean:', np.mean(accuracy))\n",
    "        print('std:', np.std(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data dimensions (4007, 256)\n",
      "eig: [2.67833574e-07 3.36558527e-07 3.69995675e-07 ... 4.29565124e-01\n",
      " 5.53495356e-01 1.00000000e+00]\n",
      "eig length: (4007,)\n",
      "cut_off: 0.11513246177898318\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration0: 0.8535127055306427\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration1: 0.8001993024414549\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration2: 0.8256103637269556\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration3: 0.8365719980069756\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration4: 0.8584952665670155\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration5: 0.817140009965122\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration6: 0.8365719980069756\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration7: 0.8315894369706028\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration8: 0.8295964125560538\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration9: 0.7987045341305431\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration10: 0.8430493273542601\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration11: 0.8440458395615347\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration12: 0.7907324364723468\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration13: 0.8251121076233184\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration14: 0.815146985550573\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration15: 0.8101644245142003\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration16: 0.807673143996014\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration17: 0.8026905829596412\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration18: 0.8026905829596412\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration19: 0.8241155954160438\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration20: 0.8465371200797209\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration21: 0.7882411559541604\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration22: 0.8011958146487295\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration23: 0.7508719481813653\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration24: 0.7957149975087194\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration25: 0.8390632785251619\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration26: 0.809666168410563\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration27: 0.8231190832087693\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration28: 0.8365719980069756\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration29: 0.794718485301445\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration30: 0.8435475834578974\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration31: 0.8380667663178873\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration32: 0.8036870951669158\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration33: 0.7952167414050823\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration34: 0.8036870951669158\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration35: 0.7887394120577977\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration36: 0.8405580468360737\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration37: 0.8121574489287494\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration38: 0.8480318883906328\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration39: 0.8106626806178375\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration40: 0.8470353761833582\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration41: 0.8450423517688092\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration42: 0.8545092177379173\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration43: 0.8599900348779272\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration44: 0.8400597907324364\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration45: 0.8570004982561036\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration46: 0.8236173393124065\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration47: 0.7867463876432487\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration48: 0.7329347284504235\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "accuracy at iteration49: 0.8056801195814649\n",
      "[0.85351271 0.8001993  0.82561036 0.836572   0.85849527 0.81714001\n",
      " 0.836572   0.83158944 0.82959641 0.79870453 0.84304933 0.84404584\n",
      " 0.79073244 0.82511211 0.81514699 0.81016442 0.80767314 0.80269058\n",
      " 0.80269058 0.8241156  0.84653712 0.78824116 0.80119581 0.75087195\n",
      " 0.795715   0.83906328 0.80966617 0.82311908 0.836572   0.79471849\n",
      " 0.84354758 0.83806677 0.8036871  0.79521674 0.8036871  0.78873941\n",
      " 0.84055805 0.81215745 0.84803189 0.81066268 0.84703538 0.84504235\n",
      " 0.85450922 0.85999003 0.84005979 0.8570005  0.82361734 0.78674639\n",
      " 0.73293473 0.80568012]\n",
      "mean: 0.8195216741405084\n",
      "std: 0.026513834211991036\n"
     ]
    }
   ],
   "source": [
    "get_mean_and_std(partition,method='cluster_kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "import sys\n",
    "class extension_cluster_kernel:\n",
    "    def __init__(self, data, type, parameters=None):\n",
    "        self.dict = {}\n",
    "        for i,d in enumerate(data):\n",
    "            self.dict[str(d)] = i\n",
    "        sigma=6\n",
    "        gam = 1/(2*sigma**2)\n",
    "        K = rbf_kernel(data,gamma = gam)\n",
    "        D = np.zeros((K.shape[0],K.shape[1]))\n",
    "        diagonalElements = np.sum(K,axis = 1)\n",
    "        for i in range(D.shape[0]):\n",
    "            D[i,i] = diagonalElements[i]**(-0.5)\n",
    "        L = (D.dot(K)).dot(D)\n",
    "        self.L = L\n",
    "        self.eigvalues,self.eigvectors = np.linalg.eigh(L)\n",
    "        if parameters:\n",
    "            self.K = getattr(self, type)(parameters)\n",
    "        else:\n",
    "            self.K = getattr(self, type)()\n",
    "    def compute_K(self,L):\n",
    "        D_hat = np.diag((1./(np.diagonal(L) + sys.float_info.epsilon))**(0.5))\n",
    "        K_hat = (D_hat.dot(L)).dot(D_hat)\n",
    "        return K_hat\n",
    "    def linear(self):\n",
    "        return self.compute_K(self.L)\n",
    "    def step(self,lambda_cut):\n",
    "        tmp_eig = np.zeros((len(self.eigvalues),len(self.eigvalues)))\n",
    "        for i,e in enumerate(self.eigvalues):\n",
    "            if e >= lambda_cut:\n",
    "                tmp_eig[i,i] = 1\n",
    "            else:\n",
    "                tmp_eig[i,i] = 0\n",
    "        L_hat = (self.eigvectors.dot(tmp_eig)).dot(self.eigvectors.T)\n",
    "        self.K = self.compute_K(L_hat)\n",
    "        return self.K\n",
    "    def linear_step(self,r):\n",
    "        tmp_eig = np.diag(self.eigvalues)\n",
    "        for i,e in enumerate(self.eigvalues):\n",
    "            if e < r:\n",
    "                tmp_eig[i,i] = 0\n",
    "        L_hat = (self.eigvectors.dot(tmp_eig)).dot(self.eigvectors.T)\n",
    "        self.K = self.compute_K(L_hat)\n",
    "        return self.K\n",
    "    def polynomial(self,t):\n",
    "        tmp_eig = np.diag(np.power(self.eigvalues,t))\n",
    "        L_hat = (self.eigvectors.dot(tmp_eig)).dot(self.eigvectors.T)\n",
    "        self.K = self.compute_K(L_hat)\n",
    "        return self.K\n",
    "    def poly_step(self,parameter_list):\n",
    "        cut_off = parameter_list[0]\n",
    "        p = parameter_list[1]\n",
    "        q = parameter_list[2]\n",
    "        tmp_eig = np.zeros((len(self.eigvalues),len(self.eigvalues)))\n",
    "        for i,e in enumerate(self.eigvalues):\n",
    "            if e>=cut_off:\n",
    "                tmp_eig[i,i] = np.power(e,p)\n",
    "            else:\n",
    "                tmp_eig[i,i] = np.power(e,q)\n",
    "        L_hat = (self.eigvectors.dot(tmp_eig)).dot(self.eigvectors.T)\n",
    "        self.K = self.compute_K(L_hat)\n",
    "        return self.K\n",
    "    \n",
    "    def distance(self,X1,X2):\n",
    "            gram_matrix = np.zeros((X1.shape[0], X2.shape[0]))\n",
    "            index2list = np.zeros((X2.shape[0]),dtype=int)\n",
    "            for j, x2 in enumerate(X2):\n",
    "                index2list[j] = self.dict[str(x2)]\n",
    "            for i, x1 in enumerate(X1):\n",
    "                ind1 = self.dict[str(x1)]\n",
    "                gram_matrix[i, :] = self.K[ind1,index2list]\n",
    "            return gram_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 256)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "data = df_usps_sample.iloc[:,1:].to_numpy()\n",
    "targets = df_usps_sample.iloc[:,0].to_numpy()\n",
    "print(data.shape)\n",
    "print(targets.shape)\n",
    "my_kernel = extension_cluster_kernel(data,'linear_step',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(my_kernel.K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel=<bound method extension_cluster_kernel.distance of <__main__.extension_cluster_kernel object at 0x0000026487D84898>>,\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "index = np.random.permutation(data.shape[0])\n",
    "\n",
    "train_data = data[index[:40]]\n",
    "Y = targets[index[:40]]\n",
    "\n",
    "clf = svm.SVC(kernel = my_kernel.distance, C=100)\n",
    "#clf = svm.SVC(kernel = 'precomputed')\n",
    "\n",
    "#print(Y)\n",
    "#print(train_data)\n",
    "\n",
    "clf.fit(train_data,Y)\n",
    "#clf.fit(my_kernel.distance(train_data,train_data),Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1960, 256)\n",
      "(1960,)\n"
     ]
    }
   ],
   "source": [
    "test_data = data[index[40:2000]]\n",
    "y_test = targets[index[40:2000]]\n",
    "print(test_data.shape)\n",
    "print(y_test.shape)\n",
    "#clf.score(test_data,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(my_kernel.distance(train_data,test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.475\n"
     ]
    }
   ],
   "source": [
    "print(pred[pred==y_test].size/pred.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1]\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1  1 -1  1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1]\n"
     ]
    }
   ],
   "source": [
    "print(pred[pred==y_test])\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "def k_th_largest_eig(eig,k):\n",
    "    arr = eig.copy()\n",
    "    arr.sort() \n",
    "    return arr[-k]\n",
    "\n",
    "ex = [1,2,3,4,5,6,7]\n",
    "print(k_th_largest_eig(ex,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_ker = extension_cluster_kernel(data,'poly_step',[cut_off,1/2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.12272936e-06 5.36717222e-06 5.70439497e-06 ... 6.36924305e-01\n",
      " 7.44778433e-01 1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "eigenv = lin_ker.eigvalues\n",
    "print(eigenv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24595535248034162\n"
     ]
    }
   ],
   "source": [
    "cut_off = k_th_largest_eig(eigenv,15)\n",
    "print(cut_off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.16820461,  0.07673395, ...,  0.0084723 ,\n",
       "         0.00751655,  0.02843456],\n",
       "       [ 0.16820461,  1.        ,  0.88072997, ...,  0.59363339,\n",
       "         0.25046989,  0.61090089],\n",
       "       [ 0.07673395,  0.88072997,  1.        , ...,  0.46465528,\n",
       "         0.19522036,  0.30295858],\n",
       "       ...,\n",
       "       [ 0.0084723 ,  0.59363339,  0.46465528, ...,  1.        ,\n",
       "         0.71298524,  0.32859715],\n",
       "       [ 0.00751655,  0.25046989,  0.19522036, ...,  0.71298524,\n",
       "         1.        , -0.06475393],\n",
       "       [ 0.02843456,  0.61090089,  0.30295858, ...,  0.32859715,\n",
       "        -0.06475393,  1.        ]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_ker.linear_step(cut_off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel=<bound method extension_cluster_kernel.distance of <__main__.extension_cluster_kernel object at 0x0000026488063828>>,\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel = lin_ker.distance, C = 1000)\n",
    "clf.fit(train_data,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8112244897959183"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(test_data,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.00119113,  0.03364855, ..., -0.00997191,\n",
       "        -0.02174076, -0.01350418],\n",
       "       [ 0.00119113,  1.        ,  0.1156237 , ...,  0.17011473,\n",
       "         0.08906751,  0.11379243],\n",
       "       [ 0.03364855,  0.1156237 ,  1.        , ..., -0.05278648,\n",
       "         0.03754403, -0.1303005 ],\n",
       "       ...,\n",
       "       [-0.00997191,  0.17011473, -0.05278648, ...,  1.        ,\n",
       "         0.18297684,  0.54376966],\n",
       "       [-0.02174076,  0.08906751,  0.03754403, ...,  0.18297684,\n",
       "         1.        ,  0.14113327],\n",
       "       [-0.01350418,  0.11379243, -0.1303005 , ...,  0.54376966,\n",
       "         0.14113327,  1.        ]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_ker.poly_step([cut_off,1/2,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
