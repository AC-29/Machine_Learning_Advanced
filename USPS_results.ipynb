{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USPS_results replication\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "from tsvm import TSVM\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "with open ('usbs_databases', 'rb') as fp:\n",
    "    usps_file = pickle.load(fp) \n",
    "\n",
    "partition = usps_file[0]\n",
    "df_usps_sample = usps_file[1]\n",
    "df_usps_test = usps_file[2]\n",
    "\n",
    "def k_th_largest_eig(eig,k):\n",
    "    arr = eig.copy()\n",
    "    arr.sort() \n",
    "    return arr[-k]\n",
    "\n",
    "\n",
    "def get_mean_and_std(partition,gram='0',method='svm'):\n",
    "    sigma=6\n",
    "    accuracy = np.zeros(50)\n",
    "    gam = 1/(2*sigma**2)\n",
    "    if(method=='cluster_kernel'): #cluster kernel\n",
    "        '''trn = df_usps_sample.iloc[:,1:].to_numpy()\n",
    "        tes = df_usps_test.iloc[:,1:].to_numpy()\n",
    "        data = np.concatenate((trn,tes),axis=0)\n",
    "        print('data dimensions', data.shape)'''\n",
    "        '''lin_ker = extension_cluster_kernel(trn,'linear')\n",
    "        eig = lin_ker.eigvalues\n",
    "        print('eig:',eig)\n",
    "        print('eig length:',eig.shape)\n",
    "        cut_off = k_th_largest_eig(eig,15)\n",
    "        print('cut_off:',cut_off)\n",
    "        lin_ker.poly_step([cut_off,1/2,1])'''\n",
    "        for i in range(50):\n",
    "            #for each i, use partition[i] as train, and the rest as test\n",
    "            data_partition = partition[i].iloc[:,1:]\n",
    "            targets = partition[i].iloc[:,0].to_numpy()\n",
    "            inputs =  data_partition.to_numpy()\n",
    "            #print(inputs)\n",
    "            unlabeled_df = df_usps_sample.drop(partition[i].index) #'drop' simply ingores the indeces from particion [i], giving us the 'rest'\n",
    "            unlabeled_targets=unlabeled_df.iloc[:,0].to_numpy()\n",
    "            unlabeled_inputs =unlabeled_df.iloc[:,1:].to_numpy()\n",
    "            test_df = df_usps_test\n",
    "            test_inputs = test_df.iloc[:,1:].to_numpy()\n",
    "            test_targets= test_df.iloc[:,0].to_numpy()\n",
    "            \n",
    "            trn = np.concatenate((inputs,unlabeled_inputs))\n",
    "            lin_ker = extension_cluster_kernel(trn,'linear')\n",
    "            eig = lin_ker.eigvalues\n",
    "            #print('eig:',eig)\n",
    "            #print('eig length:',eig.shape)\n",
    "            cut_off = k_th_largest_eig(eig,15)\n",
    "            #print('cut_off:',cut_off)\n",
    "            lin_ker.poly_step([cut_off,1/2,1])\n",
    "            \n",
    "            \n",
    "            clf = svm.SVC(kernel=lin_ker.distanceGeneral, C=100,class_weight='balanced')\n",
    "            print('number of +1:',targets[targets==1].shape)\n",
    "            print('number of -1:',targets[targets==-1].shape)\n",
    "            clf.fit(inputs,targets)\n",
    "            accuracy[i] = clf.score(test_inputs,test_targets)\n",
    "            print('accuracy at iteration'+str(i)+':',accuracy[i]) \n",
    "        print(accuracy)\n",
    "        print('mean:', np.mean(accuracy))\n",
    "        print('std:', np.std(accuracy))\n",
    "    elif(method=='svm'): #svm\n",
    "        for i in range(50):\n",
    "            #for each i, use partition[i] as train, and the rest as test\n",
    "            data_partition = partition[i].iloc[:,1:]\n",
    "            targets = partition[i].iloc[:,0].to_numpy()\n",
    "            #data_partition = df_usps_sample.iloc[:,1:]\n",
    "            #targets = df_usps_sample.iloc[:,0].to_numpy()\n",
    "            inputs =  data_partition.to_numpy()\n",
    "            test_df = df_usps_test\n",
    "            test_targets=test_df.iloc[:,0].to_numpy()\n",
    "            test_inputs =test_df.iloc[:,1:].to_numpy()\n",
    "            #print(inputs_scaled.std(axis=0))\n",
    "            #pca = PCA(n_components = 0.95, svd_solver='full')\n",
    "            #pca.fit(inputs)\n",
    "            #transformed_inputs = pca.transform(inputs)\n",
    "            #transformed_test_inputs = pca.transform(test_inputs)\n",
    "            clf = svm.SVC(kernel='rbf', C=100,gamma=gam,class_weight='balanced')\n",
    "            clf.fit(inputs, targets)\n",
    "            accuracy[i] = clf.score(test_inputs,test_targets)\n",
    "            print('accuracy at iteration'+str(i)+':',accuracy[i])\n",
    "        print('sigma:', sigma)\n",
    "        print(accuracy)\n",
    "        print('mean:', np.mean(accuracy))\n",
    "        print('std:', np.std(accuracy))\n",
    "    elif(method=='tsvm'): #tsvm\n",
    "\n",
    "        for i in range(50):\n",
    "            #for each i, use partition[i] as train, and the rest as test\n",
    "            data_partition = partition[i].iloc[:,1:]\n",
    "            targets = partition[i].iloc[:,0].to_numpy()\n",
    "            inputs =  data_partition.to_numpy()\n",
    "            unlabeled_df = df_usps_sample.drop(partition[i].index) #'drop' simply ingores the indeces from particion [i], giving us the 'rest'\n",
    "            unlabeled_targets=unlabeled_df.iloc[:,0].to_numpy()\n",
    "            unlabeled_inputs =unlabeled_df.iloc[:,1:].to_numpy()\n",
    "            test_df = df_usps_test\n",
    "            test_inputs = test_df.iloc[:,1:].to_numpy()\n",
    "            test_targets= test_df.iloc[:,0].to_numpy()\n",
    "            clf = TSVM()\n",
    "            gamma = gam \n",
    "            C = 10\n",
    "            clf.initial('rbf',gam,C)\n",
    "            print(targets)\n",
    "            clf.train(inputs,targets,unlabeled_inputs)\n",
    "            test_predict = clf.predict(test_inputs)\n",
    "            accuracy[i] = test_predict[test_predict==test_targets].size/test_predict.size\n",
    "            print(accuracy[i])\n",
    "            #clf = svm.SVC(kernel='rbf', C=10,gamma=gam,class_weight='balanced')\n",
    "            #clf.fit(inputs, targets)\n",
    "            #accuracy[i] = clf.score(test_inputs,test_targets)\n",
    "        print(accuracy)\n",
    "        print('mean:', np.mean(accuracy))\n",
    "        print('std:', np.std(accuracy))\n",
    "    else: #random walk\n",
    "        \n",
    "        for i in range(50):\n",
    "            #for each i, use partition[i] as train, and the rest as test\n",
    "            data_partition = partition[i].iloc[:,1:]\n",
    "            targets = partition[i].iloc[:,0].to_numpy()\n",
    "            inputs =  data_partition.to_numpy()\n",
    "            unlabeled_df = df_usps_sample.drop(partition[i].index) #'drop' simply ingores the indeces from particion [i], giving us the 'rest'\n",
    "            unlabeled_targets=unlabeled_df.iloc[:,0].to_numpy()\n",
    "            unlabeled_inputs =unlabeled_df.iloc[:,1:].to_numpy()\n",
    "            test_df = df_usps_test\n",
    "            test_inputs = test_df.iloc[:,1:].to_numpy()\n",
    "            test_targets= test_df.iloc[:,0].to_numpy()\n",
    "            \n",
    "            unl_total = np.concatenate((unlabeled_inputs,test_inputs))\n",
    "            \n",
    "            rw = random_walk(inputs,targets,unl_total,gam,2,4)\n",
    "            res = rw.results\n",
    "            print(res)\n",
    "            print(res.shape)\n",
    "            #test_predict = clf.predict(test_inputs)\n",
    "            #accuracy[i] = \n",
    "            #print(accuracy[i])\n",
    "            predicted_res = res[40:]\n",
    "            print(predicted_res.shape)\n",
    "            targ = np.concatenate((unlabeled_targets,test_targets))\n",
    "            accuracy[i] = targ[targ==predicted_res].shape[0]/targ.shape[0]\n",
    "            print(accuracy[i])\n",
    "            #clf = svm.SVC(kernel='rbf', C=10,gamma=gam,class_weight='balanced')\n",
    "            #clf.fit(inputs, targets)\n",
    "            #accuracy[i] = clf.score(test_inputs,test_targets)\n",
    "        print(accuracy)\n",
    "        print('mean:', np.mean(accuracy))\n",
    "        print('std:', np.std(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[ 0.04232945 -0.00359036 -0.01180845 ...  0.02176844  0.04164054\n",
      "  -0.00853262]\n",
      " [-0.00179734  0.03360361  0.01685422 ...  0.0200525   0.276622\n",
      "   0.00801866]\n",
      " [ 0.00149801  0.06085257 -0.02610445 ...  0.01352914  0.04956195\n",
      "  -0.00597817]\n",
      " ...\n",
      " [ 0.21266026  0.04301656  0.05308995 ...  0.04050648 -0.00188894\n",
      "  -0.02509798]\n",
      " [ 0.1587895  -0.0091046   0.02532049 ...  0.04471847  0.00309389\n",
      "   0.04034302]\n",
      " [ 0.17717756  0.03037018  0.0578368  ...  0.13065738 -0.00101405\n",
      "  -0.02264693]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration0: 0.8659691081215745\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[ 1.83897217e-02  3.99674421e-02 -6.54857650e-03 ...  1.36958036e-02\n",
      "   2.52377510e-02 -1.80497252e-04]\n",
      " [-1.24620310e-02  3.99809185e-02 -2.41312761e-02 ...  2.20639691e-02\n",
      "   5.10503356e-02 -1.42048074e-02]\n",
      " [-3.15196297e-02 -1.00132664e-02 -3.64031557e-02 ... -4.66036968e-03\n",
      "   2.44270938e-02 -1.60545562e-02]\n",
      " ...\n",
      " [ 3.26432863e-02  6.00910596e-03 -1.38459331e-02 ...  3.48247096e-02\n",
      "  -1.49392053e-03  4.56699544e-02]\n",
      " [ 3.13142344e-01  1.16616106e-02  1.32392390e-02 ...  8.36984807e-02\n",
      "  -4.03115488e-04  9.51827882e-02]\n",
      " [-5.37288515e-02  3.61919130e-02 -5.45215392e-02 ...  2.70934194e-02\n",
      "   1.22086188e-03  9.65281572e-02]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration1: 0.8500249128051819\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[ 0.00738451  0.02143655  0.01424241 ... -0.00352363  0.0297908\n",
      "   0.00460311]\n",
      " [-0.01274841 -0.02730063 -0.03276905 ...  0.00670567  0.1993836\n",
      "  -0.00953463]\n",
      " [ 0.03570023 -0.04231701 -0.00849607 ...  0.00553607  0.09339719\n",
      "  -0.00342216]\n",
      " ...\n",
      " [ 0.34046396  0.03155139  0.04182781 ...  0.03979048  0.00647784\n",
      "   0.02111928]\n",
      " [ 0.20976193  0.01606171  0.01046978 ...  0.04760392  0.00674193\n",
      "   0.00897141]\n",
      " [-0.04257621  0.02474182 -0.04487707 ...  0.04194056  0.0028697\n",
      "   0.11251863]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration2: 0.820627802690583\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[-2.02400823e-02  5.58567943e-02 -2.33581416e-02 ...  1.48180373e-02\n",
      "   2.17490740e-03 -1.17827585e-02]\n",
      " [ 1.79314882e-04  3.17806599e-02  3.63599523e-02 ...  3.43870914e-03\n",
      "  -3.05339553e-02 -1.87080771e-02]\n",
      " [ 1.93413521e-02  3.83794099e-02  4.55032697e-02 ... -8.73913949e-03\n",
      "   1.73702612e-01  2.94306560e-02]\n",
      " ...\n",
      " [ 1.33128894e-01  2.22750667e-03  3.90665482e-02 ...  5.53168333e-02\n",
      "  -4.09188718e-03  3.19975335e-02]\n",
      " [ 1.15128136e-01 -2.10291255e-04  1.41950879e-02 ...  5.21334976e-02\n",
      "   1.64088704e-04  1.58329151e-02]\n",
      " [ 2.60222359e-01 -2.49884993e-03  3.79961190e-02 ...  5.22123967e-02\n",
      "  -2.67870737e-03  3.73417649e-02]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration3: 0.8530144494270054\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[-0.03486698  0.00863753 -0.04633525 ...  0.00843978  0.17131943\n",
      "  -0.01542306]\n",
      " [-0.01702251  0.09879379 -0.03510964 ...  0.0264077   0.02820239\n",
      "  -0.01501202]\n",
      " [-0.02066507 -0.00872758 -0.04061406 ...  0.00856066  0.16775788\n",
      "  -0.01056405]\n",
      " ...\n",
      " [ 0.05352581  0.006325   -0.03174852 ...  0.0658559   0.00039489\n",
      "   0.17196227]\n",
      " [ 0.03755873  0.00267908 -0.02684639 ...  0.05952691 -0.00453788\n",
      "   0.32515922]\n",
      " [-0.04190897  0.01285875 -0.0506292  ...  0.02515907  0.00966717\n",
      "   0.25993421]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration4: 0.861484803188839\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[-9.52272036e-04  9.23244138e-02  5.71719934e-03 ...  1.47608123e-02\n",
      "   3.68589687e-01  3.53992590e-03]\n",
      " [ 2.69447111e-03  1.03184307e-01  2.43544674e-02 ...  1.53667879e-02\n",
      "  -4.58470143e-02 -1.97058333e-02]\n",
      " [ 2.69369155e-02 -5.91985675e-03  3.04898173e-04 ...  3.68901738e-02\n",
      "   1.20139490e-01  7.50062319e-03]\n",
      " ...\n",
      " [ 1.92471207e-01  2.97553389e-02  5.83738929e-02 ...  4.19904187e-02\n",
      "   1.14843859e-02 -1.17108447e-02]\n",
      " [ 1.11250124e-01  1.79108687e-02  7.92609994e-02 ...  4.04168722e-02\n",
      "  -3.78529797e-03 -3.82882074e-02]\n",
      " [-2.38994145e-02  2.64667724e-02 -4.20269272e-02 ...  3.13536639e-02\n",
      "   5.96819138e-03  7.85314705e-02]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration5: 0.8365719980069756\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[ 1.59601585e-03  4.52506207e-02 -1.00208437e-02 ...  1.15089031e-02\n",
      "  -5.86131276e-02 -6.31399149e-03]\n",
      " [ 1.28290351e-02  3.98003209e-02  1.44966285e-02 ... -5.13816387e-04\n",
      "  -1.08632746e-01 -2.45441222e-02]\n",
      " [ 2.08015904e-04 -5.46657339e-02 -2.85931611e-02 ... -4.91758939e-03\n",
      "   6.03032155e-02 -8.37703991e-03]\n",
      " ...\n",
      " [ 1.27716614e-01  3.78861372e-02  4.97598769e-02 ...  9.84196374e-02\n",
      "  -3.72323313e-03 -5.13486174e-03]\n",
      " [ 3.49388776e-01  2.55879189e-03  9.94676433e-02 ...  9.72457944e-02\n",
      "   8.23867318e-04  5.11986925e-03]\n",
      " [-2.39102112e-02  2.64792334e-02 -3.27200876e-02 ...  3.69504843e-02\n",
      "   1.29152720e-03  1.06936622e-01]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration6: 0.84853014449427\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[ 0.00715666  0.04995339  0.00844223 ...  0.0167758   0.29409206\n",
      "   0.00919311]\n",
      " [-0.00360001  0.03792254 -0.02718652 ...  0.00558468  0.05074782\n",
      "  -0.01449849]\n",
      " [-0.00158635 -0.02099027 -0.01138554 ... -0.0096277   0.02420794\n",
      "   0.04377023]\n",
      " ...\n",
      " [ 0.48274448  0.00999454  0.09095242 ...  0.08828985  0.00436421\n",
      "   0.0123335 ]\n",
      " [ 0.04353622 -0.00162448 -0.0478374  ...  0.01620372  0.01017585\n",
      "   0.16929171]\n",
      " [ 0.36408046  0.00709247  0.04598969 ...  0.03871438  0.00505104\n",
      "   0.02856812]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration7: 0.8480318883906328\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[-0.00716639  0.11080155 -0.02826683 ...  0.02011367 -0.00034879\n",
      "  -0.00686056]\n",
      " [ 0.03271517  0.01847446  0.01488591 ...  0.03594132  0.01148859\n",
      "  -0.03546203]\n",
      " [ 0.04825545 -0.00340545  0.02921575 ...  0.02971974  0.31283978\n",
      "   0.00865291]\n",
      " ...\n",
      " [ 0.05877859  0.01047182 -0.03424473 ...  0.02146247  0.01006475\n",
      "   0.07574801]\n",
      " [ 0.15267203 -0.00221577  0.01936795 ...  0.0764929  -0.00313735\n",
      "   0.09542205]\n",
      " [ 0.30074296  0.01328493  0.07217405 ...  0.03312659  0.00443571\n",
      "   0.00055744]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration8: 0.8455406078724464\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[-2.20356382e-03  6.10015485e-02 -5.55066592e-03 ...  7.53958465e-03\n",
      "   1.96847350e-01  1.48671320e-02]\n",
      " [ 1.07562575e-02  5.90052602e-05  4.61177573e-02 ... -5.88281962e-03\n",
      "   6.03989789e-01  2.12962516e-02]\n",
      " [-6.07273916e-03 -4.50764481e-02 -2.48550652e-02 ... -1.46085175e-02\n",
      "   1.14613317e-02  9.47533225e-03]\n",
      " ...\n",
      " [ 4.25409136e-01 -1.04212829e-02  1.05538256e-01 ...  5.94632139e-02\n",
      "  -1.33542731e-03  1.23083380e-02]\n",
      " [ 1.12013461e-01  4.26409994e-03 -2.69072128e-02 ...  2.91988747e-02\n",
      "  -4.62159411e-03  1.17720469e-01]\n",
      " [ 8.20734880e-02 -4.62494936e-03 -3.08254705e-02 ...  2.70890794e-02\n",
      "   1.24079628e-03  1.06300126e-01]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration9: 0.8176382660687593\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[-2.46068222e-02 -1.65438651e-02 -2.54798088e-02 ...  6.46911630e-03\n",
      "   1.76032701e-01 -1.59326944e-02]\n",
      " [ 2.73905000e-02 -1.78131907e-03  2.90294466e-02 ...  2.15276291e-02\n",
      "   1.54710429e-01 -8.48628767e-03]\n",
      " [-1.34414238e-02 -6.97538060e-03  8.54266372e-02 ...  2.22884556e-04\n",
      "   4.36917019e-02 -9.49989470e-03]\n",
      " ...\n",
      " [ 7.25106649e-01  1.38212504e-02  9.22889479e-02 ...  6.13857605e-02\n",
      "   1.15298513e-02  5.89256841e-03]\n",
      " [ 1.11837753e-01  3.29180664e-03  2.82879527e-02 ...  4.53413904e-02\n",
      "  -4.12207086e-03  6.53109570e-03]\n",
      " [ 9.27577524e-02 -3.02823742e-03 -2.87556013e-02 ...  4.61046600e-02\n",
      "   2.55558273e-03  1.61649011e-01]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration10: 0.8550074738415545\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[-0.00245377  0.0063186   0.01321439 ...  0.00854568  0.42676725\n",
      "   0.01480089]\n",
      " [-0.02083732 -0.00902521 -0.02885146 ...  0.00724656  0.3306402\n",
      "  -0.0183996 ]\n",
      " [-0.02285738 -0.034926    0.00644072 ... -0.01008786  0.02422946\n",
      "  -0.00399717]\n",
      " ...\n",
      " [ 0.52108846  0.00765987  0.10685419 ...  0.06089496  0.00459195\n",
      "  -0.01113786]\n",
      " [ 0.30948156  0.00281427  0.05680787 ...  0.03122847  0.01416798\n",
      "   0.02813246]\n",
      " [ 0.34012805  0.01825769  0.06114775 ...  0.08872506  0.00187123\n",
      "   0.03694713]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration11: 0.8530144494270054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[ 2.73604733e-03 -4.72580985e-02 -3.47935322e-02 ...  3.14373706e-03\n",
      "   7.61326381e-02  3.21118415e-03]\n",
      " [ 1.01989163e-02  1.56992072e-02  3.37940056e-02 ... -8.95133212e-03\n",
      "   4.06493443e-01  2.02992073e-02]\n",
      " [-3.62020529e-02 -1.95560811e-02  5.08705043e-03 ... -1.68020352e-02\n",
      "  -5.92728990e-03  1.45438843e-02]\n",
      " ...\n",
      " [ 1.75226649e-01 -5.45364025e-03  2.43889533e-02 ...  3.97462545e-02\n",
      "  -1.11277135e-02  8.41778061e-02]\n",
      " [ 1.75915747e-01 -6.44157917e-04  1.65281650e-02 ...  2.02175246e-02\n",
      "  -3.16873545e-03  3.21379021e-02]\n",
      " [ 7.56979458e-03  1.93465929e-02 -2.34220692e-02 ...  6.34119782e-02\n",
      "   3.65275613e-04  8.74685451e-02]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration12: 0.8251121076233184\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[ 4.79842115e-03  6.94767107e-02 -2.15034250e-02 ...  6.35279593e-03\n",
      "  -7.88630670e-02 -1.31946169e-02]\n",
      " [-2.43817980e-02  2.85475609e-02  5.76400317e-02 ...  1.40556360e-02\n",
      "   3.47295225e-02 -2.00358364e-02]\n",
      " [ 3.51889826e-02  2.52774540e-02  4.69406489e-02 ...  1.97952775e-02\n",
      "   5.32352755e-02 -3.55092950e-03]\n",
      " ...\n",
      " [ 3.15779431e-01  1.33498584e-02  3.67497699e-02 ...  1.13963602e-01\n",
      "   3.23747548e-03  4.18903875e-02]\n",
      " [ 9.68348672e-02  1.66021794e-02 -1.27757460e-04 ...  3.95480231e-02\n",
      "  -1.58879492e-03 -1.29581894e-02]\n",
      " [ 8.96635979e-02 -1.08302597e-02 -3.62047965e-02 ...  2.36280257e-02\n",
      "   5.67144722e-03  1.98084907e-01]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration13: 0.8400597907324364\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[ 0.00156021  0.06857347  0.0027457  ...  0.03446717 -0.0446055\n",
      "  -0.02319907]\n",
      " [ 0.0657219  -0.02473169  0.01468927 ...  0.01694707  0.06385678\n",
      "   0.0181224 ]\n",
      " [ 0.00099014 -0.0047352  -0.00878563 ...  0.01170585  0.15201584\n",
      "  -0.00366142]\n",
      " ...\n",
      " [ 0.01152324  0.01395661 -0.05099512 ...  0.02380122  0.01026041\n",
      "   0.17421159]\n",
      " [ 0.00971162 -0.00204573 -0.05367887 ...  0.02554658  0.01177319\n",
      "   0.25815643]\n",
      " [ 0.29399018 -0.00778242  0.07290352 ...  0.05642054  0.00030526\n",
      "   0.02478082]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration14: 0.833582461385152\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[-9.49935696e-03  2.82517001e-02 -5.38981724e-03 ...  1.59762159e-02\n",
      "  -2.36311540e-02 -2.54222147e-02]\n",
      " [-4.19235650e-03 -2.47110941e-02 -1.24022750e-02 ...  2.81876514e-03\n",
      "   2.95219300e-02 -1.96172489e-02]\n",
      " [ 2.61300732e-02 -3.87771633e-03  7.91587117e-02 ...  2.14339388e-02\n",
      "   5.16933856e-05 -4.18982769e-02]\n",
      " ...\n",
      " [ 5.69657996e-02 -3.97276549e-03 -4.54457092e-02 ...  2.71621989e-02\n",
      "   2.37890930e-03  1.68066993e-01]\n",
      " [ 3.18297784e-01 -2.49633081e-03  2.68648119e-02 ...  3.09781153e-02\n",
      "   6.97432193e-03  3.49797809e-02]\n",
      " [ 1.70370109e-01 -1.72789894e-02 -4.75268674e-04 ...  2.94445116e-02\n",
      "   1.01094162e-02  1.17573194e-01]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration15: 0.817140009965122\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[ 0.01018308 -0.02495177 -0.02206501 ...  0.01621043  0.01167828\n",
      "   0.0082019 ]\n",
      " [ 0.03752439 -0.0147482  -0.00231319 ...  0.01045314  0.04877119\n",
      "  -0.0104294 ]\n",
      " [ 0.00322769  0.05934918 -0.00581669 ...  0.01358432 -0.08155957\n",
      "   0.002079  ]\n",
      " ...\n",
      " [-0.0587572   0.02705101 -0.03493063 ...  0.07003614 -0.00516869\n",
      "   0.1709116 ]\n",
      " [ 0.20114617  0.00048999  0.0708673  ...  0.10824801 -0.0013247\n",
      "   0.04782952]\n",
      " [-0.04519913  0.02752979 -0.0573232  ...  0.02723748  0.00330654\n",
      "   0.13186894]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration16: 0.8241155954160438\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[ 0.00967806  0.03754061 -0.01550583 ... -0.00749466 -0.06651563\n",
      "  -0.00678952]\n",
      " [-0.00862082 -0.02538831 -0.03015124 ...  0.00081944  0.19593914\n",
      "  -0.01797936]\n",
      " [ 0.02142754  0.0105709   0.0215557  ... -0.00504595  0.03548905\n",
      "   0.00915958]\n",
      " ...\n",
      " [ 0.32720238 -0.00439643  0.09480985 ...  0.08769848  0.0022836\n",
      "   0.02601491]\n",
      " [ 0.17131773 -0.00659387 -0.01192532 ...  0.02935564  0.00329332\n",
      "   0.06122723]\n",
      " [-0.04151769  0.02248688 -0.05591281 ...  0.02532862  0.00493936\n",
      "   0.12021429]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration17: 0.8161434977578476\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[ 6.27503080e-03  1.24472985e-02  2.72139284e-02 ... -2.01337282e-03\n",
      "   3.94387058e-01  1.64353901e-02]\n",
      " [ 1.73353623e-02  1.17488370e-02  3.34674277e-02 ... -1.31859536e-02\n",
      "   2.68756608e-01  2.37069124e-02]\n",
      " [-1.08611908e-02  1.59489314e-01 -3.72061900e-02 ...  3.17682145e-02\n",
      "   1.03045268e-01 -1.31000287e-02]\n",
      " ...\n",
      " [ 5.94166375e-01  8.88737378e-03  9.00809882e-02 ...  6.57577135e-02\n",
      "   6.87713082e-03 -1.24834979e-02]\n",
      " [-5.54760694e-02  1.96330259e-02 -3.07887036e-02 ...  7.84315701e-02\n",
      "  -5.56670890e-06  2.01834774e-01]\n",
      " [ 5.15129268e-02  3.34673431e-03 -2.67912965e-02 ...  3.45956674e-02\n",
      "  -8.02388690e-03  1.17396675e-01]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration18: 0.8086696562032885\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[-0.01262978 -0.00376271 -0.03007555 ... -0.00384058 -0.03088281\n",
      "  -0.02498569]\n",
      " [-0.01090627 -0.00259484 -0.00716116 ...  0.02442321  0.12619864\n",
      "  -0.01314275]\n",
      " [ 0.0788621   0.04027383 -0.0236048  ...  0.04702615  0.02176143\n",
      "   0.00652639]\n",
      " ...\n",
      " [ 0.28113565  0.00637142  0.02792286 ...  0.05488352 -0.00472742\n",
      "   0.0727676 ]\n",
      " [-0.00755266  0.02379181 -0.04535416 ...  0.03815344  0.0027526\n",
      "   0.08492855]\n",
      " [ 0.02243362  0.03887266 -0.00974128 ...  0.05488343 -0.00240196\n",
      "   0.01824683]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration19: 0.8380667663178873\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[ 3.80927065e-02 -2.98674893e-02  1.46925926e-02 ...  1.05287778e-02\n",
      "   2.24795140e-01 -1.63740845e-03]\n",
      " [-9.15492343e-03  3.06040286e-02 -9.76771629e-03 ...  1.01338334e-02\n",
      "   3.15432140e-01 -2.48096564e-03]\n",
      " [-1.71194734e-04  3.00312900e-02  3.50103420e-02 ...  2.64982813e-02\n",
      "  -1.14828883e-03 -2.43469465e-02]\n",
      " ...\n",
      " [-2.69953881e-02  2.26989186e-02 -2.42927314e-02 ...  7.30625539e-02\n",
      "   5.80941267e-03  1.47895284e-01]\n",
      " [ 1.98557074e-01 -3.86475806e-03 -9.55862927e-03 ...  2.60436614e-02\n",
      "   1.33546496e-04  8.18874895e-02]\n",
      " [ 4.74127606e-01 -5.20618646e-03  8.59315516e-02 ...  6.18406966e-02\n",
      "   4.73887861e-03  1.44740829e-02]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration20: 0.8624813153961136\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[ 7.78364644e-03  4.84937323e-02 -8.73576910e-03 ...  3.42624390e-03\n",
      "  -8.75843885e-02 -1.17708048e-02]\n",
      " [-2.11629350e-02  6.58381776e-02 -2.26535269e-02 ...  2.22962599e-02\n",
      "   3.15440376e-01 -1.28000866e-02]\n",
      " [ 3.13261839e-04 -3.34945669e-02 -8.12343999e-03 ...  3.52799740e-03\n",
      "   1.73926741e-01 -1.20157926e-02]\n",
      " ...\n",
      " [ 1.99634865e-01  4.95733902e-02  1.04480123e-02 ...  4.09186957e-02\n",
      "  -1.36204769e-03 -2.09167774e-02]\n",
      " [ 4.26778177e-02  6.04710894e-03 -2.82768251e-02 ...  2.89979911e-02\n",
      "   2.43929996e-03  9.77085135e-02]\n",
      " [ 8.05924763e-02  1.92283418e-02  2.96953563e-02 ...  2.97630113e-02\n",
      "   1.14270405e-03 -4.95048455e-02]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration21: 0.7972097658196313\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[-0.00125464 -0.05154323 -0.03099084 ... -0.00995936  0.0381725\n",
      "  -0.00907382]\n",
      " [ 0.02425042  0.032878    0.04736184 ...  0.00401184  0.17206806\n",
      "   0.01612609]\n",
      " [ 0.00815134  0.01100886  0.01825302 ... -0.01388209  0.00688535\n",
      "   0.01023971]\n",
      " ...\n",
      " [ 0.09025648  0.0121709   0.00543778 ...  0.01487762  0.02811374\n",
      "   0.04885004]\n",
      " [ 0.36110553  0.02333107  0.08125417 ...  0.06062465  0.00458735\n",
      "  -0.03633773]\n",
      " [ 0.03794217  0.01447624 -0.02420687 ...  0.03469252  0.00044891\n",
      "   0.06366286]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration22: 0.8111609367214748\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[ 0.02192613 -0.02542344 -0.01980144 ...  0.00565716  0.26891869\n",
      "  -0.00524209]\n",
      " [ 0.00502638 -0.00868731  0.03898368 ... -0.00680249  0.38929751\n",
      "   0.01497894]\n",
      " [ 0.0017256  -0.00305386  0.00819668 ...  0.00411682  0.31825729\n",
      "  -0.01797213]\n",
      " ...\n",
      " [ 0.26728031  0.02062694  0.0328783  ...  0.04666439  0.00059634\n",
      "   0.01013068]\n",
      " [ 0.1722128   0.00998452  0.02529801 ...  0.03842334  0.00582526\n",
      "   0.02806626]\n",
      " [ 0.14063231 -0.01037219 -0.00149081 ...  0.04393021  0.01016345\n",
      "   0.12513951]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration23: 0.7663178873941205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[ 1.83200059e-02  1.08796421e-02  3.84341732e-02 ...  2.59198223e-02\n",
      "   3.23992227e-03 -3.57905211e-02]\n",
      " [ 4.86637359e-03  1.21504890e-02  1.20047190e-03 ...  3.43548294e-02\n",
      "   4.65987598e-02 -1.39317344e-02]\n",
      " [ 1.29299330e-02 -3.49054418e-03  2.75549882e-02 ... -5.26805161e-04\n",
      "   5.13594091e-01  2.99207428e-04]\n",
      " ...\n",
      " [ 4.25199918e-01  1.30310796e-02  7.99755868e-02 ...  5.08987404e-02\n",
      "   3.30371313e-04 -1.76686419e-02]\n",
      " [ 2.54140074e-01 -1.13143741e-02  6.84249581e-02 ...  5.44823979e-02\n",
      "   3.14059944e-03  4.59407954e-02]\n",
      " [ 2.46767427e-01  5.51860478e-03  2.10593467e-02 ...  4.76973904e-02\n",
      "   5.49652810e-03  1.90337197e-02]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration24: 0.809666168410563\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[ 0.01718944  0.03989361  0.00305904 ...  0.02542029  0.02234922\n",
      "  -0.00530868]\n",
      " [-0.02648255 -0.01084361  0.0280488  ... -0.0056366   0.05461968\n",
      "  -0.007831  ]\n",
      " [-0.00558043 -0.03321277 -0.02462324 ... -0.00621086  0.07765079\n",
      "  -0.00120665]\n",
      " ...\n",
      " [ 0.18631437  0.00300182 -0.00861512 ...  0.036616    0.00862854\n",
      "   0.12865671]\n",
      " [ 0.12233732  0.01654396 -0.01930237 ...  0.02524626 -0.00165401\n",
      "   0.01895164]\n",
      " [ 0.00385689  0.02233688 -0.05668448 ...  0.01393392 -0.00204884\n",
      "   0.24690341]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration25: 0.8500249128051819\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[-0.01111898 -0.03435509  0.00772661 ... -0.01047385  0.0337133\n",
      "   0.02663009]\n",
      " [-0.00408199  0.01813949 -0.02662878 ...  0.01192662  0.01749341\n",
      "  -0.01202022]\n",
      " [ 0.00089621  0.02698459  0.01440971 ...  0.00329259  0.35611188\n",
      "   0.01928847]\n",
      " ...\n",
      " [ 0.14058534 -0.00102626  0.0683034  ...  0.06500669  0.00238748\n",
      "  -0.01376368]\n",
      " [ 0.03789425  0.03130575  0.03698696 ...  0.04835158  0.00407287\n",
      "   0.01487434]\n",
      " [ 0.13067517  0.01512625 -0.01381525 ...  0.02639714  0.01631018\n",
      "   0.0540095 ]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration26: 0.8256103637269556\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[-0.00839599 -0.01269582 -0.03968506 ...  0.00194     0.01967795\n",
      "  -0.01382409]\n",
      " [ 0.01569438  0.04452667  0.0330656  ... -0.00096717  0.20549749\n",
      "   0.02274637]\n",
      " [-0.02064366  0.02117137 -0.00493419 ...  0.01710106  0.05668469\n",
      "  -0.0135412 ]\n",
      " ...\n",
      " [ 0.60095563  0.04108237  0.07377178 ...  0.07409165  0.00251596\n",
      "  -0.01025966]\n",
      " [ 0.26900438 -0.01035184  0.07385324 ...  0.05323094 -0.00273114\n",
      "  -0.01563022]\n",
      " [ 0.03818253  0.02284641 -0.02626774 ...  0.0781636   0.01063428\n",
      "   0.14465275]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration27: 0.833582461385152\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[ 0.00090707  0.15655514 -0.02225487 ...  0.02562051  0.0428177\n",
      "   0.00332285]\n",
      " [ 0.01394114 -0.03731756 -0.02544608 ... -0.01055882  0.00974906\n",
      "   0.0138875 ]\n",
      " [-0.00748714 -0.01707494 -0.03437206 ...  0.00506057  0.09160594\n",
      "  -0.00986815]\n",
      " ...\n",
      " [-0.02989984  0.01391156 -0.05679075 ...  0.0004095   0.01089684\n",
      "   0.36723124]\n",
      " [ 0.10488558  0.01441224 -0.01684224 ...  0.03673784 -0.00120024\n",
      "   0.04973365]\n",
      " [-0.04974616  0.02213285 -0.043934   ...  0.04657853  0.00336394\n",
      "   0.22077518]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration28: 0.8405580468360737\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[-0.03282361  0.00953172 -0.00475654 ...  0.00659162  0.01992632\n",
      "  -0.01490462]\n",
      " [ 0.01269244 -0.02729836 -0.03706601 ...  0.01124482  0.13459361\n",
      "   0.00331627]\n",
      " [-0.01083513  0.01178465 -0.00261455 ...  0.00489952  0.34374835\n",
      "  -0.01573802]\n",
      " ...\n",
      " [ 0.14031418  0.03174706  0.04845515 ...  0.04135257  0.00827026\n",
      "  -0.02645007]\n",
      " [ 0.01084157 -0.00058785 -0.0525891  ...  0.02086135  0.01659769\n",
      "   0.30302227]\n",
      " [ 0.09009585  0.00962987 -0.01328319 ...  0.0318952  -0.00183205\n",
      "   0.03128272]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration29: 0.8161434977578476\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[ 0.02027593  0.03861863 -0.0135055  ...  0.00466525 -0.07073947\n",
      "  -0.01045643]\n",
      " [-0.00978886  0.11139011 -0.02757748 ...  0.0150534  -0.01623446\n",
      "  -0.00623988]\n",
      " [ 0.0047391   0.00783807  0.02653248 ...  0.0139973   0.06741214\n",
      "  -0.00597672]\n",
      " ...\n",
      " [ 0.20029845 -0.00756485  0.04385416 ...  0.03414874 -0.00519661\n",
      "   0.00778933]\n",
      " [ 0.05230329  0.01943116 -0.03207731 ...  0.03464467 -0.00068411\n",
      "   0.08050294]\n",
      " [ 0.08068441  0.0120655   0.01390958 ...  0.04709709 -0.00312542\n",
      "  -0.00916075]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration30: 0.8565022421524664\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[-0.01041787  0.10009775 -0.01373764 ...  0.02735333  0.13826618\n",
      "  -0.01382818]\n",
      " [ 0.0654876  -0.01999503  0.03677551 ...  0.03227186  0.03000948\n",
      "   0.01380713]\n",
      " [-0.02619917 -0.02562959 -0.04834232 ... -0.00380845  0.08534674\n",
      "  -0.01557417]\n",
      " ...\n",
      " [ 0.05771506  0.01411855  0.04677213 ...  0.07875905 -0.00316873\n",
      "   0.03110433]\n",
      " [-0.03769526  0.02002902 -0.04138367 ...  0.0390329   0.00199508\n",
      "   0.08906631]\n",
      " [ 0.08769468  0.01648563  0.04054277 ...  0.04486875  0.00391753\n",
      "   0.00973928]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration31: 0.8425510712506228\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[-0.00248593  0.0876605  -0.02798358 ...  0.02308596  0.07784924\n",
      "  -0.02562973]\n",
      " [ 0.00672816 -0.00070763 -0.01194989 ...  0.01850872  0.02048688\n",
      "  -0.01513965]\n",
      " [-0.01581001  0.06763466 -0.02054611 ...  0.02336162  0.19050798\n",
      "  -0.01867408]\n",
      " ...\n",
      " [-0.01812175  0.02914638 -0.03726841 ...  0.00897704  0.00920575\n",
      "   0.22792484]\n",
      " [ 0.02515129  0.02509732  0.02356051 ...  0.01390814  0.00107597\n",
      "  -0.01257097]\n",
      " [ 0.16087169 -0.0075101  -0.00161138 ...  0.04350527  0.00499878\n",
      "   0.08166691]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration32: 0.8201295465869457\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[-0.02480951  0.03225774 -0.03813873 ...  0.00875707 -0.02638945\n",
      "  -0.01329472]\n",
      " [-0.01938126  0.01668559 -0.02000002 ...  0.01896928  0.13722695\n",
      "  -0.00363038]\n",
      " [-0.01438804  0.16671884 -0.03778795 ...  0.02595795  0.04861282\n",
      "  -0.01660854]\n",
      " ...\n",
      " [ 0.11408454 -0.00595798  0.0629876  ...  0.04438818 -0.00202955\n",
      "   0.0022683 ]\n",
      " [ 0.05710952  0.00354936  0.02845816 ...  0.10963509 -0.01454887\n",
      "   0.20283209]\n",
      " [ 0.46254919  0.00930148  0.04213616 ...  0.05011612  0.003102\n",
      "   0.01496581]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration33: 0.8101644245142003\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[-1.16901309e-02  4.82525315e-02  3.03856055e-02 ...  1.27078420e-02\n",
      "   1.50818404e-01 -7.74986480e-03]\n",
      " [ 1.04923274e-02  1.73217169e-01  5.27251239e-04 ...  9.81060270e-03\n",
      "   4.71719430e-02  2.09342559e-03]\n",
      " [ 4.85937169e-03  3.89889839e-02 -3.20166328e-02 ...  6.29411553e-03\n",
      "   4.18749960e-02 -3.19109458e-05]\n",
      " ...\n",
      " [ 4.50203840e-01  1.68597673e-02  8.11466612e-02 ...  4.89514250e-02\n",
      "   8.77251259e-03  7.70121562e-03]\n",
      " [ 2.11987680e-01  2.52157054e-02  1.09484610e-02 ...  4.21477520e-02\n",
      "   1.47151733e-02 -1.03843752e-02]\n",
      " [ 5.46744759e-01  3.45210646e-02  5.23306648e-02 ...  6.59018029e-02\n",
      "   1.30039813e-02  8.74567511e-03]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration34: 0.8176382660687593\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[ 1.42164240e-02  4.89616127e-02  1.86249137e-03 ... -9.62005317e-03\n",
      "  -3.45144196e-02 -2.31505063e-03]\n",
      " [-5.45290697e-03  1.25774988e-02 -3.93071546e-02 ...  2.04464895e-02\n",
      "   1.22887218e-02  1.35912586e-01]\n",
      " [ 1.92071083e-02  3.66056986e-02  7.40996376e-03 ... -1.01434641e-02\n",
      "   1.50838336e-01  1.67242823e-02]\n",
      " ...\n",
      " [ 5.15030202e-01 -1.38404013e-03  1.21078282e-01 ...  5.34567843e-02\n",
      "   4.54910405e-03 -1.96470263e-02]\n",
      " [ 4.81447045e-01  4.07692541e-04  9.04421190e-02 ...  1.06960557e-01\n",
      "   2.70012297e-03  1.30489166e-02]\n",
      " [ 6.84766135e-02  8.71552871e-04 -1.36721342e-02 ...  6.06451484e-02\n",
      "  -5.11666007e-03  1.13051755e-01]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration35: 0.8001993024414549\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[-0.00465284  0.02182629  0.01058678 ...  0.00322107  0.49235377\n",
      "  -0.00252363]\n",
      " [ 0.03215521 -0.03069467 -0.00921305 ...  0.00750938  0.05691413\n",
      "   0.00299885]\n",
      " [ 0.00948893  0.11851072 -0.00267449 ...  0.00924813 -0.09219342\n",
      "  -0.01995632]\n",
      " ...\n",
      " [ 0.03890821  0.0233523  -0.00447482 ...  0.06365054  0.00483189\n",
      "   0.01215878]\n",
      " [-0.02398922  0.02480821 -0.0446092  ...  0.0187871   0.00505614\n",
      "   0.06147556]\n",
      " [ 0.36916062 -0.00501659  0.04974667 ...  0.04590682 -0.00081125\n",
      "   0.03470432]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration36: 0.8505231689088192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[-2.83623639e-02 -3.02189584e-02 -2.68236246e-02 ... -8.18451564e-03\n",
      "   7.46480201e-03 -1.67760999e-02]\n",
      " [ 2.10244556e-02 -1.14744916e-02 -7.69360191e-03 ...  1.95482926e-02\n",
      "   3.89233017e-02 -1.17807591e-02]\n",
      " [ 1.75369379e-02  1.71637805e-02  4.85412856e-02 ... -1.57674733e-04\n",
      "   5.60123499e-01  2.97873631e-02]\n",
      " ...\n",
      " [ 2.70183340e-01 -2.03916649e-03  1.88469527e-02 ...  6.92569192e-02\n",
      "  -1.06420431e-03  1.04317431e-01]\n",
      " [ 1.09833093e-01  4.05286387e-03  7.36633285e-02 ...  5.56322400e-02\n",
      "  -1.42508850e-03 -1.22900234e-03]\n",
      " [-5.88495041e-02  1.94238946e-02 -5.02248863e-02 ...  2.50570013e-02\n",
      "   1.45760318e-04  2.86755086e-01]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration37: 0.8131539611360239\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[-0.00096541  0.07138174  0.00144252 ...  0.02132893 -0.04245438\n",
      "  -0.00790652]\n",
      " [ 0.02433158  0.00594655  0.01201632 ...  0.02184562  0.28930091\n",
      "   0.00920492]\n",
      " [ 0.01170096  0.0096314   0.0488827  ... -0.0120191   0.25238331\n",
      "   0.02020943]\n",
      " ...\n",
      " [-0.03904512  0.02085403 -0.05626466 ...  0.05311775  0.00212135\n",
      "   0.16797902]\n",
      " [ 0.38253657  0.01312309  0.02719749 ...  0.05156914  0.02573175\n",
      "   0.04248987]\n",
      " [ 0.17135703  0.03853672  0.0466566  ...  0.04093839 -0.00075653\n",
      "  -0.02407163]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration38: 0.8624813153961136\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[ 3.12677101e-02 -2.96320420e-02 -3.07619588e-02 ...  3.89711953e-03\n",
      "   2.76770969e-02 -9.07368413e-04]\n",
      " [ 1.06197335e-02 -2.56364667e-02 -2.50903420e-02 ...  1.24424173e-04\n",
      "   3.05175483e-02  3.57132402e-02]\n",
      " [ 8.28024226e-03 -1.64558682e-02 -3.05708963e-02 ...  4.13379059e-03\n",
      "   2.10380373e-01 -7.83313195e-03]\n",
      " ...\n",
      " [ 2.26557390e-01  2.46915144e-02  3.03289333e-02 ...  4.69083196e-02\n",
      "   9.16896477e-04  3.60607525e-02]\n",
      " [ 2.28685053e-02  1.31540641e-02 -3.54930755e-02 ...  6.02520349e-02\n",
      "  -4.37150767e-03  1.11734359e-01]\n",
      " [ 2.05179679e-01 -8.66352143e-03  4.27202230e-02 ...  3.73041923e-02\n",
      "   1.65741980e-02  4.39818704e-02]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration39: 0.8231190832087693\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[ 3.03351624e-03  4.22493612e-02 -1.63930503e-02 ...  2.63761034e-03\n",
      "   3.56243656e-03 -1.00328771e-02]\n",
      " [ 1.88300294e-03 -3.51841371e-02 -2.07849916e-02 ... -1.09107995e-02\n",
      "   9.75999821e-03  1.13458976e-03]\n",
      " [-8.95076241e-03 -3.87586197e-02 -2.66720819e-03 ...  1.79007339e-04\n",
      "   1.19519797e-01 -1.11360342e-02]\n",
      " ...\n",
      " [ 3.08234833e-01  3.49614739e-02  3.48311776e-02 ...  4.83043114e-02\n",
      "   2.73863456e-03 -3.06038606e-02]\n",
      " [ 1.59471318e-02  1.80627391e-02 -4.34078631e-02 ...  3.06899637e-02\n",
      "   1.54589111e-03  8.28306501e-02]\n",
      " [ 4.61379412e-01  1.04351759e-02  7.22947468e-02 ...  4.85478247e-02\n",
      "   2.65128139e-03 -1.47850511e-02]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration40: 0.8545092177379173\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[ 1.51852774e-02  7.26199510e-02  3.11448319e-02 ... -1.25045140e-03\n",
      "   1.36319239e-01  2.32926969e-02]\n",
      " [ 3.94230042e-03  8.81841195e-03  2.18448357e-02 ... -7.37396606e-03\n",
      "   3.22171617e-01  2.05522605e-02]\n",
      " [ 1.67088905e-02  1.86725514e-02  7.36554776e-04 ... -4.51827343e-03\n",
      "   9.23366891e-02  7.94407845e-03]\n",
      " ...\n",
      " [ 1.03658722e-01  1.24719598e-02  6.54839790e-02 ...  7.23750589e-02\n",
      "  -5.78941306e-03 -3.57233891e-02]\n",
      " [ 8.77623401e-02  8.18092844e-03  3.00187788e-02 ...  5.06383074e-02\n",
      "  -1.60403742e-06 -2.07431551e-02]\n",
      " [ 1.42388053e-01 -5.78351903e-03  4.87854692e-02 ...  1.56620960e-02\n",
      "  -1.11481235e-03  1.71054568e-03]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration41: 0.85949177877429\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[ 0.01499174 -0.02827456 -0.02851899 ...  0.00816038  0.04965643\n",
      "   0.01210425]\n",
      " [-0.00669295  0.06618178 -0.02458437 ...  0.02077396  0.12669312\n",
      "  -0.01051611]\n",
      " [-0.01991705 -0.02156349 -0.01082448 ...  0.00285017  0.12780927\n",
      "  -0.01217929]\n",
      " ...\n",
      " [ 0.31855202 -0.00687067  0.04825241 ...  0.04826198 -0.00216864\n",
      "   0.01788425]\n",
      " [ 0.08747284  0.00598952  0.0052795  ...  0.03005072  0.00781494\n",
      "   0.01571537]\n",
      " [-0.02054512  0.0103194  -0.06913325 ...  0.00585812  0.00731416\n",
      "   0.18226959]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration42: 0.8654708520179372\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[ 0.01991746  0.02102828  0.03876979 ... -0.0040684   0.22122951\n",
      "   0.01072464]\n",
      " [-0.02215976 -0.05328292 -0.00885394 ... -0.00979228  0.02339865\n",
      "   0.02452626]\n",
      " [ 0.00163544  0.06474164 -0.01635286 ...  0.01931788  0.00937605\n",
      "  -0.01655766]\n",
      " ...\n",
      " [ 0.18882852  0.01572158  0.0723497  ...  0.0418912  -0.00556237\n",
      "  -0.04990553]\n",
      " [ 0.11528614  0.01089389 -0.00261743 ...  0.06083067  0.00097426\n",
      "   0.05178653]\n",
      " [ 0.14736211  0.01072778  0.06515608 ...  0.01977158  0.0072552\n",
      "  -0.01171095]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration43: 0.8734429496761336\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[-0.04197085 -0.01069587 -0.00333361 ... -0.01378358  0.00544434\n",
      "  -0.00699605]\n",
      " [-0.03403025  0.01860726 -0.00206786 ...  0.00352351 -0.01461871\n",
      "  -0.00429878]\n",
      " [ 0.01921552  0.02983924  0.01981354 ... -0.0110804   0.13384272\n",
      "   0.02163827]\n",
      " ...\n",
      " [ 0.07195148  0.00399395  0.02657857 ...  0.06850093  0.00187923\n",
      "   0.05191498]\n",
      " [ 0.15279462  0.0031383   0.0624057  ...  0.03266773  0.00137595\n",
      "  -0.01175264]\n",
      " [ 0.01787429  0.02170448  0.01460937 ...  0.0777161  -0.01471057\n",
      "   0.19843722]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration44: 0.8574987543597409\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[-0.00677653 -0.00192576 -0.00807734 ...  0.00927643  0.1142357\n",
      "  -0.02246473]\n",
      " [-0.01173839 -0.00514531 -0.02384903 ...  0.01035317  0.16804618\n",
      "  -0.00435516]\n",
      " [ 0.00656816  0.07053762  0.0369699  ...  0.01179059  0.04999028\n",
      "  -0.00178491]\n",
      " ...\n",
      " [ 0.13022344  0.01596129 -0.03075011 ...  0.07139955 -0.00145844\n",
      "   0.10295339]\n",
      " [ 0.22400947  0.00208552  0.00747814 ...  0.01131882 -0.00602847\n",
      "   0.0395388 ]\n",
      " [ 0.12496119  0.00507843 -0.00345436 ...  0.1293189   0.00563464\n",
      "   0.1386672 ]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration45: 0.8659691081215745\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[-0.00632258 -0.05655875 -0.03262065 ... -0.02281308  0.0115099\n",
      "  -0.0036895 ]\n",
      " [ 0.02556835  0.02913054  0.0207518  ...  0.02062061  0.00226112\n",
      "  -0.01464578]\n",
      " [-0.02089099  0.00491063 -0.04045011 ...  0.00696028  0.11203502\n",
      "  -0.01454721]\n",
      " ...\n",
      " [ 0.19724283  0.00834919  0.06424097 ...  0.06922555 -0.0097891\n",
      "   0.00457961]\n",
      " [ 0.21285534  0.02423144  0.01154838 ...  0.03340241  0.00614891\n",
      "  -0.01627357]\n",
      " [ 0.00734354  0.0134734  -0.0454089  ...  0.01032805  0.00218322\n",
      "   0.17303728]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration46: 0.8440458395615347\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[-6.86695348e-03  5.53029821e-02  3.45318337e-02 ...  2.37169838e-02\n",
      "  -3.31264414e-02 -2.28525718e-02]\n",
      " [-2.04812403e-02 -1.75135381e-02 -3.45483007e-02 ... -9.98919211e-03\n",
      "  -2.11528547e-02 -1.95642866e-02]\n",
      " [-2.38499587e-02 -5.75600329e-03  5.92013614e-02 ... -3.99797984e-03\n",
      "   2.05797815e-02  5.58922020e-03]\n",
      " ...\n",
      " [ 1.15189109e-02  1.33904588e-02 -4.05969057e-03 ...  4.66611014e-02\n",
      "   2.61488940e-03  5.30933828e-02]\n",
      " [-1.89348816e-02  1.82118892e-02 -6.62159235e-02 ...  5.67222124e-03\n",
      "  -2.44338931e-05  1.97496958e-01]\n",
      " [ 1.20445657e-01  2.13938512e-02 -2.08386611e-02 ...  4.21114566e-02\n",
      "   1.11782508e-02  1.05658854e-01]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration47: 0.8001993024414549\n",
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[ 0.01514233  0.03453972 -0.00562921 ... -0.00306585 -0.11604889\n",
      "  -0.01923427]\n",
      " [ 0.01137089  0.03248562 -0.00725692 ...  0.00125932 -0.00638946\n",
      "   0.00295913]\n",
      " [ 0.01203873  0.03964332 -0.00753366 ... -0.00290113 -0.11865819\n",
      "  -0.01899727]\n",
      " ...\n",
      " [ 0.07164223  0.01777423 -0.03693575 ...  0.03972757  0.00816532\n",
      "   0.10208613]\n",
      " [ 0.31942219  0.03973073  0.04008899 ...  0.04880112  0.00890052\n",
      "   0.00829964]\n",
      " [ 0.26633286  0.01574099  0.01760412 ...  0.03650729  0.0128718\n",
      "   0.01375635]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration48: 0.7553562531141006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of +1: (20,)\n",
      "number of -1: (20,)\n",
      "I am in second branch\n",
      "(2000, 2007)\n",
      "Projection [[ 0.00568317  0.09367342  0.03275735 ...  0.01351342  0.05038198\n",
      "  -0.00576434]\n",
      " [ 0.01415017  0.02640947  0.02087933 ... -0.01456512  0.01492644\n",
      "   0.00973138]\n",
      " [ 0.00472228 -0.03975055 -0.02165389 ... -0.01536769  0.01234126\n",
      "   0.04584536]\n",
      " ...\n",
      " [ 0.3191433   0.02895889  0.03169904 ...  0.07042195  0.00464231\n",
      "   0.02146943]\n",
      " [ 0.30581202  0.02743891  0.04674245 ...  0.0622159   0.03539136\n",
      "   0.00910962]\n",
      " [ 0.13600667 -0.00630335  0.00267588 ...  0.06311369  0.00218647\n",
      "   0.07825099]]\n",
      "size (40, 2007)\n",
      "accuracy at iteration49: 0.8320876930742401\n",
      "[0.86596911 0.85002491 0.8206278  0.85301445 0.8614848  0.836572\n",
      " 0.84853014 0.84803189 0.84554061 0.81763827 0.85500747 0.85301445\n",
      " 0.82511211 0.84005979 0.83358246 0.81714001 0.8241156  0.8161435\n",
      " 0.80866966 0.83806677 0.86248132 0.79720977 0.81116094 0.76631789\n",
      " 0.80966617 0.85002491 0.82561036 0.83358246 0.84055805 0.8161435\n",
      " 0.85650224 0.84255107 0.82012955 0.81016442 0.81763827 0.8001993\n",
      " 0.85052317 0.81315396 0.86248132 0.82311908 0.85450922 0.85949178\n",
      " 0.86547085 0.87344295 0.85749875 0.86596911 0.84404584 0.8001993\n",
      " 0.75535625 0.83208769]\n",
      "mean: 0.8335127055306429\n",
      "std: 0.02498584410379163\n"
     ]
    }
   ],
   "source": [
    "get_mean_and_std(partition,method='cluster_kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "import sys\n",
    "class extension_cluster_kernel:\n",
    "    def __init__(self, data, type, parameters=None):\n",
    "        self.dict = {}\n",
    "        self.data = data\n",
    "        for i,d in enumerate(data):\n",
    "            self.dict[str(d)] = i\n",
    "        sigma=6\n",
    "        self.gam = 1/(2*sigma**2)\n",
    "        K = rbf_kernel(data,gamma=self.gam)\n",
    "        self.rbfK = K\n",
    "        self.invRbfK = np.linalg.inv(self.rbfK)\n",
    "        D = np.zeros((K.shape[0],K.shape[1]))\n",
    "        diagonalElements = np.sum(K,axis = 1)\n",
    "        for i in range(D.shape[0]):\n",
    "            D[i,i] = diagonalElements[i]**(-0.5)\n",
    "        L = (D.dot(K)).dot(D)\n",
    "        self.L = L\n",
    "        self.eigvalues,self.eigvectors = np.linalg.eigh(L)\n",
    "        if parameters:\n",
    "            self.K = getattr(self, type)(parameters)\n",
    "        else:\n",
    "            self.K = getattr(self, type)()\n",
    "    def compute_K(self,L):\n",
    "        D_hat = np.diag((1./(np.diagonal(L) + sys.float_info.epsilon))**(0.5))\n",
    "        K_hat = (D_hat.dot(L)).dot(D_hat)\n",
    "        return K_hat\n",
    "    def linear(self):\n",
    "        return self.compute_K(self.L)\n",
    "    def step(self,lambda_cut):\n",
    "        tmp_eig = np.zeros((len(self.eigvalues),len(self.eigvalues)))\n",
    "        for i,e in enumerate(self.eigvalues):\n",
    "            if e >= lambda_cut:\n",
    "                tmp_eig[i,i] = 1\n",
    "            else:\n",
    "                tmp_eig[i,i] = 0\n",
    "        L_hat = (self.eigvectors.dot(tmp_eig)).dot(self.eigvectors.T)\n",
    "        self.K = self.compute_K(L_hat)\n",
    "        return self.K\n",
    "    def linear_step(self,r):\n",
    "        tmp_eig = np.diag(self.eigvalues)\n",
    "        for i,e in enumerate(self.eigvalues):\n",
    "            if e < r:\n",
    "                tmp_eig[i,i] = 0\n",
    "        L_hat = (self.eigvectors.dot(tmp_eig)).dot(self.eigvectors.T)\n",
    "        self.K = self.compute_K(L_hat)\n",
    "        return self.K\n",
    "    def polynomial(self,t):\n",
    "        tmp_eig = np.diag(np.power(self.eigvalues,t))\n",
    "        L_hat = (self.eigvectors.dot(tmp_eig)).dot(self.eigvectors.T)\n",
    "        self.K = self.compute_K(L_hat)\n",
    "        return self.K\n",
    "    def poly_step(self,parameter_list):\n",
    "        cut_off = parameter_list[0]\n",
    "        p = parameter_list[1]\n",
    "        q = parameter_list[2]\n",
    "        tmp_eig = np.zeros((len(self.eigvalues),len(self.eigvalues)))\n",
    "        for i,e in enumerate(self.eigvalues):\n",
    "            if e>=cut_off:\n",
    "                tmp_eig[i,i] = np.power(e,p)\n",
    "            else:\n",
    "                tmp_eig[i,i] = np.power(e,q)\n",
    "        L_hat = (self.eigvectors.dot(tmp_eig)).dot(self.eigvectors.T)\n",
    "        self.K = self.compute_K(L_hat)\n",
    "        return self.K\n",
    "    \n",
    "    def distance(self,X1,X2):\n",
    "        gram_matrix = np.zeros((X1.shape[0], X2.shape[0]))\n",
    "        index2list = np.zeros((X2.shape[0]),dtype=int)\n",
    "        for j, x2 in enumerate(X2):\n",
    "            index2list[j] = self.dict[str(x2)]\n",
    "        for i, x1 in enumerate(X1):\n",
    "            ind1 = self.dict[str(x1)]\n",
    "            gram_matrix[i, :] = self.K[ind1,index2list]\n",
    "        return gram_matrix\n",
    "    def distanceGeneral(self,X1,X2):\n",
    "        gram_matrix = np.zeros((X1.shape[0], X2.shape[0]))\n",
    "        index2list = np.zeros((X2.shape[0]),dtype=int)\n",
    "        for j, x2 in enumerate(X2):\n",
    "            if str(x2) in self.dict:\n",
    "                index2list[j] = self.dict[str(x2)]\n",
    "            else:\n",
    "                return self.distance_test(X1,X2)\n",
    "        for i, x1 in enumerate(X1):\n",
    "            if str(x1) in self.dict:\n",
    "                ind1 = self.dict[str(x1)]\n",
    "                gram_matrix[i, :] = self.K[ind1,index2list]\n",
    "            else:\n",
    "                print('I am in second branch')\n",
    "                return self.distance_test(X2,X1).T\n",
    "        return gram_matrix\n",
    "    def distance_test(self,X1,X2):\n",
    "        index1list = np.zeros((X1.shape[0]),dtype=int)\n",
    "        for j, x1 in enumerate(X1):\n",
    "            index1list[j] = self.dict[str(x1)]\n",
    "        known_samples = self.data[index1list]\n",
    "        new_samples = X2\n",
    "        #print('multiplication of kernels', np.dot(self.K,self.invRbfK))\n",
    "        V = rbf_kernel(new_samples,self.data,gamma=self.gam)\n",
    "        temp = ((self.K).dot(self.invRbfK)).dot(V.T)\n",
    "        print(temp.shape)\n",
    "        projection = np.zeros((X1.shape[0],X2.shape[0]))\n",
    "        for i in range(X1.shape[0]):\n",
    "            ind1 = self.dict[str(X1[i])]\n",
    "            projection[i] = temp[ind1]\n",
    "        #print('K_hat:',K_hat_cut)\n",
    "        #print('inverse:',invRbfK_cut)\n",
    "        print('Projection',projection)\n",
    "        print('size', projection.shape)\n",
    "        return projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 256)\n",
      "(2000,)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-dee1e0608d02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmy_kernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextension_cluster_kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'linear_step'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-29-d570d84ab953>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, type, parameters)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0msigma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mgam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrbf_kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrbfK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvRbfK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrbfK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mrbf_kernel\u001b[1;34m(X, Y, gamma)\u001b[0m\n\u001b[0;32m    946\u001b[0m     \u001b[0mkernel_matrix\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_samples_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples_Y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m     \"\"\"\n\u001b[1;32m--> 948\u001b[1;33m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    949\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mgamma\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    950\u001b[0m         \u001b[0mgamma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[1;34m(X, Y, precomputed, dtype)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mY\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mY\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         X = Y = check_array(X, accept_sparse='csr', dtype=dtype,\n\u001b[1;32m--> 109\u001b[1;33m                             estimator=estimator)\n\u001b[0m\u001b[0;32m    110\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         X = check_array(X, accept_sparse='csr', dtype=dtype,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 542\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;31m# safely to reduce dtype induced overflows.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mis_float\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;34m'fc'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mis_float\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_safe_accumulator_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mis_float\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36m_safe_accumulator_op\u001b[1;34m(op, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    686\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2181\u001b[0m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[1;32m-> 2182\u001b[1;33m                           initial=initial, where=where)\n\u001b[0m\u001b[0;32m   2183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = df_usps_sample.iloc[:,1:].to_numpy()\n",
    "targets = df_usps_sample.iloc[:,0].to_numpy()\n",
    "print(data.shape)\n",
    "print(targets.shape)\n",
    "my_kernel = extension_cluster_kernel(data,'linear_step',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(my_kernel.K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel=<bound method extension_cluster_kernel.distance of <__main__.extension_cluster_kernel object at 0x0000026487D84898>>,\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "index = np.random.permutation(data.shape[0])\n",
    "\n",
    "train_data = data[index[:40]]\n",
    "Y = targets[index[:40]]\n",
    "\n",
    "clf = svm.SVC(kernel = my_kernel.distance, C=100)\n",
    "#clf = svm.SVC(kernel = 'precomputed')\n",
    "\n",
    "#print(Y)\n",
    "#print(train_data)\n",
    "\n",
    "clf.fit(train_data,Y)\n",
    "#clf.fit(my_kernel.distance(train_data,train_data),Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1960, 256)\n",
      "(1960,)\n"
     ]
    }
   ],
   "source": [
    "test_data = data[index[40:2000]]\n",
    "y_test = targets[index[40:2000]]\n",
    "print(test_data.shape)\n",
    "print(y_test.shape)\n",
    "#clf.score(test_data,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(my_kernel.distance(train_data,test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.475\n"
     ]
    }
   ],
   "source": [
    "print(pred[pred==y_test].size/pred.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1]\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1  1 -1  1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1]\n"
     ]
    }
   ],
   "source": [
    "print(pred[pred==y_test])\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "def k_th_largest_eig(eig,k):\n",
    "    arr = eig.copy()\n",
    "    arr.sort() \n",
    "    return arr[-k]\n",
    "\n",
    "ex = [1,2,3,4,5,6,7]\n",
    "print(k_th_largest_eig(ex,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-0fe2adeaff4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlin_ker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextension_cluster_kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'poly_step'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcut_off\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "lin_ker = extension_cluster_kernel(data,'poly_step',[cut_off,1/2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.12272936e-06 5.36717222e-06 5.70439497e-06 ... 6.36924305e-01\n",
      " 7.44778433e-01 1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "eigenv = lin_ker.eigvalues\n",
    "print(eigenv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24595535248034162\n"
     ]
    }
   ],
   "source": [
    "cut_off = k_th_largest_eig(eigenv,15)\n",
    "print(cut_off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.16820461,  0.07673395, ...,  0.0084723 ,\n",
       "         0.00751655,  0.02843456],\n",
       "       [ 0.16820461,  1.        ,  0.88072997, ...,  0.59363339,\n",
       "         0.25046989,  0.61090089],\n",
       "       [ 0.07673395,  0.88072997,  1.        , ...,  0.46465528,\n",
       "         0.19522036,  0.30295858],\n",
       "       ...,\n",
       "       [ 0.0084723 ,  0.59363339,  0.46465528, ...,  1.        ,\n",
       "         0.71298524,  0.32859715],\n",
       "       [ 0.00751655,  0.25046989,  0.19522036, ...,  0.71298524,\n",
       "         1.        , -0.06475393],\n",
       "       [ 0.02843456,  0.61090089,  0.30295858, ...,  0.32859715,\n",
       "        -0.06475393,  1.        ]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_ker.linear_step(cut_off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel=<bound method extension_cluster_kernel.distance of <__main__.extension_cluster_kernel object at 0x0000026488063828>>,\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel = lin_ker.distance, C = 1000)\n",
    "clf.fit(train_data,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8112244897959183"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(test_data,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.00119113,  0.03364855, ..., -0.00997191,\n",
       "        -0.02174076, -0.01350418],\n",
       "       [ 0.00119113,  1.        ,  0.1156237 , ...,  0.17011473,\n",
       "         0.08906751,  0.11379243],\n",
       "       [ 0.03364855,  0.1156237 ,  1.        , ..., -0.05278648,\n",
       "         0.03754403, -0.1303005 ],\n",
       "       ...,\n",
       "       [-0.00997191,  0.17011473, -0.05278648, ...,  1.        ,\n",
       "         0.18297684,  0.54376966],\n",
       "       [-0.02174076,  0.08906751,  0.03754403, ...,  0.18297684,\n",
       "         1.        ,  0.14113327],\n",
       "       [-0.01350418,  0.11379243, -0.1303005 , ...,  0.54376966,\n",
       "         0.14113327,  1.        ]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_ker.poly_step([cut_off,1/2,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class random_walk:\n",
    "    def __init__(self,labeledData,labels,unlabeledData,gam=None,k=1,t=2):\n",
    "        data = np.concatenate((labeledData,unlabeledData))\n",
    "        L = labeledData.shape[0]\n",
    "        N = data.shape[0]\n",
    "        labels = (1==labels)*1\n",
    "        self.W = rbf_kernel(data,gamma=gam)\n",
    "        for i in range((self.W).shape[0]):\n",
    "            sort = list(np.argsort(self.W[i]))\n",
    "            sort.remove(i)\n",
    "            for j in sort[k:]:\n",
    "                self.W[i,j]=0\n",
    "                \n",
    "        self.W = np.maximum(self.W,(self.W).transpose())\n",
    "        self.P=np.zeros(((self.W).shape))\n",
    "        sumRowsW = np.sum(self.W,axis=1)\n",
    "        for i in range((self.W).shape[0]):\n",
    "            self.P[i]=self.W[i]/sumRowsW[i]\n",
    "        \n",
    "        self.PT = np.linalg.matrix_power(self.P,t)\n",
    "        \n",
    "        self.labelProbability = np.zeros((N,2))\n",
    "        #Initializing random values\n",
    "        for i in range(N):\n",
    "            number = (0.5 - np.random.rand())*0.4\n",
    "            self.labelProbability[i,0] = 0.5+number\n",
    "            self.labelProbability[i,1]=1-self.labelProbability[i,0]\n",
    "        \n",
    "        self.probability = np.zeros((N,L))\n",
    "        oldloglike = -np.inf\n",
    "        self.loglike = np.zeros(100)\n",
    "        for iter in range(100):\n",
    "            #E Step\n",
    "            for i in range(N):\n",
    "                for j in range(L):\n",
    "                    self.probability[i,j] = self.labelProbability[i,labels[j]]*self.PT[i,j]\n",
    "                    \n",
    "            #M Step\n",
    "            for i in range(N):\n",
    "                self.labelProbability[i,0] = (np.sum((labels==0)*self.probability[i]))/(np.sum(self.probability[i])+sys.float_info.epsilon)\n",
    "                self.labelProbability[i,1] = (np.sum((labels==1)*self.probability[i]))/(np.sum(self.probability[i])+sys.float_info.epsilon)\n",
    "            self.loglike[iter] = np.sum(np.log(np.sum(self.probability,axis=0)))\n",
    "            if np.abs(self.loglike[iter] - oldloglike) < 10**(-4):\n",
    "                break\n",
    "            oldloglike = self.loglike[iter]\n",
    "        \n",
    "        self.posterior = np.matmul((self.labelProbability).transpose(),self.PT)\n",
    "        self.results = ((np.argmax(self.posterior,axis = 0))*2)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def JH_bound(dataTrain,targets,dataTest,datatarg):\n",
    "    data = np.concatenate((dataTrain,dataTest))\n",
    "    kern = extension_cluster_kernel(data,'linear')\n",
    "    linearEigval = -np.sort(-kern.eigvalues)[:int((dataTrain.shape[0])/2)]\n",
    "    #print(linearEigval)\n",
    "    T = np.zeros((len(linearEigval)))\n",
    "    er = np.zeros((len(linearEigval)))\n",
    "    for i,lamda_cut in enumerate(linearEigval):\n",
    "        kern.poly_step([lamda_cut,1/2,2])\n",
    "        clf = svm.SVC(C=100,kernel=kern.distance)\n",
    "        clf.fit(dataTrain,targets)\n",
    "        #print(clf.dual_coef_)\n",
    "        alphas = np.abs(clf.dual_coef_).reshape(-1)\n",
    "        #alphas = clf.dual_coef_.reshape(-1)\n",
    "        supportV = clf.support_\n",
    "        for j in range(len(alphas)):\n",
    "            T[i] += ((alphas[j]*kern.K[supportV[j],supportV[j]]-1)>0)*1\n",
    "            #print(T[i])\n",
    "        T[i] = T[i]/dataTrain.shape[0]\n",
    "        er[i] = 1-clf.score(dataTest,datatarg)\n",
    "    return T,er"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_partition = partition[0].iloc[:,1:]\n",
    "targets = partition[0].iloc[:,0].to_numpy()\n",
    "inputs =  data_partition.to_numpy()\n",
    "unlabeled_df = df_usps_sample.drop(partition[0].index) #'drop' simply ingores the indeces from particion [i], giving us the 'rest'\n",
    "unlabeled_targets=unlabeled_df.iloc[:,0].to_numpy()\n",
    "unlabeled_inputs =unlabeled_df.iloc[:,1:].to_numpy()\n",
    "test_df = df_usps_test\n",
    "test_inputs = test_df.iloc[:,1:].to_numpy()\n",
    "test_targets= test_df.iloc[:,0].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.575 0.525 0.55  0.6   0.575 0.6   0.575 0.575 0.55  0.55  0.525 0.525\n",
      "  0.4   0.375 0.4   0.325 0.375 0.375 0.425 0.4  ]\n",
      " [0.7   0.7   0.7   0.7   0.7   0.75  0.725 0.7   0.55  0.65  0.625 0.6\n",
      "  0.6   0.6   0.625 0.5   0.5   0.45  0.45  0.525]\n",
      " [0.675 0.675 0.675 0.7   0.7   0.7   0.7   0.675 0.65  0.625 0.6   0.6\n",
      "  0.625 0.6   0.55  0.45  0.5   0.45  0.475 0.5  ]\n",
      " [0.6   0.55  0.575 0.575 0.6   0.65  0.575 0.575 0.55  0.525 0.45  0.425\n",
      "  0.45  0.5   0.525 0.45  0.475 0.4   0.475 0.45 ]\n",
      " [0.75  0.8   0.8   0.775 0.825 0.775 0.775 0.775 0.725 0.675 0.675 0.7\n",
      "  0.65  0.65  0.65  0.575 0.575 0.575 0.575 0.55 ]\n",
      " [0.625 0.675 0.625 0.625 0.7   0.7   0.7   0.75  0.6   0.525 0.475 0.5\n",
      "  0.5   0.475 0.5   0.4   0.375 0.375 0.375 0.4  ]\n",
      " [0.675 0.675 0.675 0.7   0.7   0.7   0.725 0.75  0.675 0.625 0.675 0.675\n",
      "  0.625 0.525 0.55  0.45  0.5   0.5   0.475 0.5  ]\n",
      " [0.575 0.575 0.575 0.6   0.6   0.65  0.625 0.625 0.6   0.55  0.55  0.55\n",
      "  0.525 0.5   0.525 0.5   0.475 0.45  0.425 0.475]\n",
      " [0.7   0.675 0.7   0.7   0.7   0.725 0.725 0.725 0.625 0.55  0.575 0.575\n",
      "  0.55  0.55  0.55  0.45  0.475 0.525 0.425 0.425]\n",
      " [0.5   0.55  0.55  0.525 0.55  0.5   0.5   0.525 0.35  0.375 0.4   0.425\n",
      "  0.375 0.375 0.375 0.35  0.35  0.375 0.35  0.375]\n",
      " [0.525 0.55  0.525 0.6   0.575 0.625 0.65  0.65  0.525 0.575 0.525 0.5\n",
      "  0.525 0.425 0.45  0.4   0.425 0.4   0.375 0.375]\n",
      " [0.575 0.625 0.625 0.65  0.65  0.625 0.625 0.65  0.65  0.6   0.575 0.55\n",
      "  0.525 0.525 0.525 0.425 0.425 0.45  0.4   0.45 ]\n",
      " [0.65  0.675 0.625 0.675 0.65  0.675 0.675 0.65  0.6   0.575 0.6   0.55\n",
      "  0.475 0.45  0.45  0.425 0.45  0.45  0.425 0.4  ]\n",
      " [0.75  0.75  0.75  0.75  0.75  0.75  0.75  0.775 0.75  0.725 0.725 0.775\n",
      "  0.725 0.75  0.675 0.675 0.65  0.65  0.65  0.625]\n",
      " [0.7   0.7   0.7   0.7   0.75  0.75  0.7   0.625 0.625 0.525 0.525 0.575\n",
      "  0.5   0.5   0.5   0.475 0.4   0.4   0.4   0.475]\n",
      " [0.55  0.6   0.575 0.6   0.6   0.575 0.575 0.525 0.475 0.4   0.4   0.375\n",
      "  0.375 0.375 0.4   0.35  0.375 0.35  0.325 0.35 ]\n",
      " [0.55  0.575 0.55  0.55  0.575 0.55  0.575 0.575 0.45  0.45  0.45  0.425\n",
      "  0.45  0.45  0.45  0.425 0.425 0.4   0.375 0.425]\n",
      " [0.6   0.6   0.6   0.65  0.55  0.525 0.6   0.575 0.5   0.425 0.425 0.4\n",
      "  0.4   0.375 0.35  0.35  0.325 0.325 0.375 0.375]\n",
      " [0.55  0.575 0.575 0.6   0.575 0.625 0.625 0.625 0.475 0.475 0.475 0.425\n",
      "  0.425 0.45  0.45  0.425 0.4   0.4   0.4   0.45 ]\n",
      " [0.6   0.6   0.625 0.65  0.7   0.65  0.625 0.65  0.55  0.525 0.5   0.525\n",
      "  0.525 0.55  0.575 0.4   0.4   0.4   0.4   0.4  ]\n",
      " [0.525 0.525 0.525 0.5   0.525 0.525 0.575 0.575 0.475 0.45  0.45  0.45\n",
      "  0.4   0.475 0.475 0.375 0.375 0.375 0.375 0.325]\n",
      " [0.475 0.5   0.5   0.5   0.475 0.475 0.5   0.5   0.475 0.35  0.35  0.35\n",
      "  0.35  0.425 0.35  0.35  0.375 0.375 0.375 0.375]\n",
      " [0.425 0.4   0.375 0.45  0.425 0.45  0.45  0.45  0.45  0.35  0.35  0.375\n",
      "  0.35  0.3   0.3   0.275 0.325 0.3   0.3   0.275]\n",
      " [0.55  0.6   0.6   0.575 0.6   0.65  0.65  0.675 0.675 0.55  0.475 0.5\n",
      "  0.425 0.45  0.475 0.425 0.45  0.425 0.45  0.45 ]\n",
      " [0.7   0.725 0.725 0.725 0.75  0.75  0.7   0.7   0.575 0.6   0.6   0.6\n",
      "  0.575 0.625 0.55  0.375 0.4   0.4   0.425 0.475]\n",
      " [0.6   0.625 0.575 0.55  0.575 0.6   0.65  0.675 0.55  0.55  0.525 0.5\n",
      "  0.45  0.45  0.45  0.35  0.325 0.325 0.35  0.4  ]\n",
      " [0.575 0.55  0.55  0.525 0.525 0.575 0.575 0.575 0.525 0.525 0.55  0.525\n",
      "  0.5   0.45  0.425 0.35  0.35  0.4   0.425 0.425]\n",
      " [0.575 0.575 0.6   0.625 0.625 0.575 0.625 0.6   0.575 0.525 0.525 0.5\n",
      "  0.5   0.525 0.475 0.45  0.475 0.45  0.45  0.425]\n",
      " [0.625 0.625 0.625 0.65  0.7   0.7   0.725 0.75  0.65  0.575 0.525 0.575\n",
      "  0.5   0.5   0.5   0.45  0.45  0.475 0.475 0.475]\n",
      " [0.6   0.575 0.625 0.6   0.55  0.55  0.575 0.55  0.375 0.4   0.425 0.375\n",
      "  0.425 0.4   0.45  0.425 0.4   0.425 0.4   0.4  ]\n",
      " [0.625 0.625 0.625 0.625 0.625 0.625 0.625 0.6   0.55  0.5   0.525 0.475\n",
      "  0.45  0.475 0.45  0.35  0.4   0.425 0.4   0.375]\n",
      " [0.6   0.625 0.6   0.65  0.625 0.6   0.6   0.6   0.525 0.5   0.5   0.525\n",
      "  0.475 0.475 0.5   0.4   0.425 0.45  0.4   0.375]\n",
      " [0.5   0.5   0.525 0.5   0.5   0.55  0.525 0.55  0.45  0.375 0.4   0.375\n",
      "  0.4   0.4   0.35  0.375 0.375 0.4   0.4   0.4  ]\n",
      " [0.55  0.525 0.525 0.525 0.55  0.55  0.55  0.625 0.525 0.425 0.4   0.425\n",
      "  0.375 0.375 0.475 0.4   0.4   0.425 0.4   0.375]\n",
      " [0.575 0.6   0.55  0.575 0.55  0.575 0.6   0.55  0.55  0.525 0.55  0.525\n",
      "  0.525 0.525 0.55  0.5   0.5   0.5   0.5   0.525]\n",
      " [0.525 0.55  0.5   0.5   0.5   0.575 0.575 0.525 0.575 0.55  0.5   0.5\n",
      "  0.375 0.375 0.35  0.35  0.35  0.3   0.325 0.35 ]\n",
      " [0.625 0.625 0.625 0.675 0.675 0.725 0.7   0.7   0.6   0.55  0.525 0.55\n",
      "  0.525 0.525 0.55  0.475 0.45  0.375 0.475 0.45 ]\n",
      " [0.675 0.675 0.7   0.675 0.675 0.7   0.725 0.775 0.725 0.625 0.575 0.575\n",
      "  0.525 0.525 0.525 0.5   0.5   0.525 0.425 0.475]\n",
      " [0.675 0.7   0.675 0.7   0.675 0.675 0.7   0.65  0.625 0.55  0.55  0.55\n",
      "  0.575 0.55  0.55  0.525 0.55  0.55  0.525 0.525]\n",
      " [0.625 0.625 0.625 0.625 0.625 0.625 0.65  0.675 0.525 0.525 0.525 0.5\n",
      "  0.5   0.475 0.425 0.425 0.4   0.325 0.4   0.4  ]\n",
      " [0.55  0.55  0.525 0.575 0.55  0.575 0.625 0.625 0.55  0.525 0.55  0.55\n",
      "  0.45  0.45  0.425 0.425 0.4   0.425 0.325 0.35 ]\n",
      " [0.5   0.5   0.5   0.5   0.5   0.55  0.525 0.525 0.5   0.5   0.5   0.5\n",
      "  0.475 0.45  0.45  0.3   0.325 0.325 0.35  0.4  ]\n",
      " [0.55  0.575 0.575 0.55  0.525 0.575 0.65  0.65  0.6   0.425 0.425 0.45\n",
      "  0.325 0.325 0.375 0.375 0.375 0.375 0.375 0.375]\n",
      " [0.6   0.6   0.575 0.6   0.6   0.625 0.625 0.625 0.55  0.525 0.5   0.525\n",
      "  0.45  0.475 0.4   0.275 0.25  0.325 0.3   0.3  ]\n",
      " [0.5   0.5   0.55  0.575 0.575 0.575 0.6   0.625 0.55  0.475 0.425 0.475\n",
      "  0.4   0.425 0.4   0.35  0.375 0.375 0.375 0.4  ]\n",
      " [0.575 0.575 0.6   0.625 0.675 0.675 0.625 0.6   0.55  0.475 0.475 0.575\n",
      "  0.425 0.45  0.45  0.325 0.3   0.325 0.325 0.325]\n",
      " [0.575 0.575 0.575 0.575 0.575 0.575 0.6   0.55  0.475 0.475 0.5   0.45\n",
      "  0.45  0.475 0.5   0.45  0.4   0.45  0.4   0.475]\n",
      " [0.55  0.575 0.575 0.6   0.65  0.65  0.65  0.65  0.625 0.525 0.5   0.475\n",
      "  0.475 0.475 0.475 0.425 0.425 0.5   0.475 0.475]\n",
      " [0.575 0.575 0.6   0.625 0.65  0.65  0.7   0.725 0.675 0.65  0.625 0.675\n",
      "  0.5   0.525 0.45  0.4   0.4   0.4   0.45  0.475]\n",
      " [0.6   0.6   0.6   0.6   0.625 0.65  0.675 0.7   0.7   0.7   0.7   0.65\n",
      "  0.575 0.55  0.575 0.475 0.55  0.5   0.525 0.525]]\n"
     ]
    }
   ],
   "source": [
    "it=50\n",
    "s = np.zeros((it,20))\n",
    "true_err = np.zeros((it,20))\n",
    "for i in range(it):\n",
    "    data_partition = partition[i].iloc[:,1:]\n",
    "    targets = partition[i].iloc[:,0].to_numpy()\n",
    "    inputs =  data_partition.to_numpy()\n",
    "    unlabeled_df = df_usps_sample.drop(partition[i].index) #'drop' simply ingores the indeces from particion [i], giving us the 'rest'\n",
    "    unlabeled_targets=unlabeled_df.iloc[:,0].to_numpy()\n",
    "    unlabeled_inputs =unlabeled_df.iloc[:,1:].to_numpy()\n",
    "    test_df = df_usps_test\n",
    "    test_inputs = test_df.iloc[:,1:].to_numpy()\n",
    "    test_targets= test_df.iloc[:,0].to_numpy()\n",
    "    tst = np.concatenate((unlabeled_inputs,test_inputs))\n",
    "    tst_targ = np.concatenate((unlabeled_targets,test_targets))\n",
    "    s[i],true_err[i] = JH_bound(inputs,targets,tst,tst_targ)\n",
    "\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02862897 0.02849359 0.02815891 0.02931054 0.02933607 0.02811707\n",
      " 0.02937774 0.03303435 0.03357058 0.02969435 0.03106414 0.03052331\n",
      " 0.03054304 0.02899824 0.03037554 0.03255957 0.03408579 0.0329077\n",
      " 0.03271283 0.03148696]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x25281043d30>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#print(true_err)\n",
    "s_mean = s.mean(axis=0)\n",
    "#s_m = s_mean[6:]\n",
    "s_var = s.std(axis=0)\n",
    "#s_v = s_var[6:]\n",
    "err_mean = true_err.mean(axis=0)\n",
    "#err_m = err_mean[6:]\n",
    "err_var = true_err.std(axis=0)\n",
    "print(err_var)\n",
    "#err_v = err_var[6:]\n",
    "#print(s_mean)\n",
    "#print(s_var)\n",
    "i = range(6,s_mean.shape[0])\n",
    "plt.errorbar(i,s_mean[6:], yerr=s_var[6:], fmt='-o',label='Jaakkola-Haussler bound')\n",
    "plt.errorbar(i,err_mean[6:], yerr=err_var[6:], fmt='-^',label='Test error')\n",
    "plt.xlabel('r')\n",
    "plt.ylabel('error')\n",
    "plt.legend()\n",
    "#plt.plot(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x252804f34e0>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(s[0])\n",
    "plt.plot(true_err[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
