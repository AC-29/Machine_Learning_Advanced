{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kernel stuff\n",
    "sig=0.5\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "import sys\n",
    "class extension_cluster_kernel:\n",
    "    def __init__(self, data, type, parameters=None):\n",
    "        self.dict = {}\n",
    "        for i,d in enumerate(data):\n",
    "            self.dict[d.tobytes()] = i\n",
    "        sigma=sig\n",
    "        gam = 1/(2*sigma**2)\n",
    "        K = rbf_kernel(data,gamma = gam)\n",
    "        D = np.zeros((K.shape[0],K.shape[1]))\n",
    "        diagonalElements = np.sum(K,axis = 1)\n",
    "        for i in range(D.shape[0]):\n",
    "            D[i,i] = diagonalElements[i]**(-0.5)\n",
    "        L = (D.dot(K)).dot(D)\n",
    "        self.L = L\n",
    "        self.eigvalues,self.eigvectors = np.linalg.eigh(L)\n",
    "        if parameters:\n",
    "            self.K = getattr(self, type)(parameters)\n",
    "        else:\n",
    "            self.K = getattr(self, type)()\n",
    "    def compute_K(self,L):\n",
    "        D_hat = np.diag((1./(np.diagonal(L) + sys.float_info.epsilon))**(0.5))\n",
    "        K_hat = (D_hat.dot(L)).dot(D_hat)\n",
    "        return K_hat\n",
    "    def linear(self):\n",
    "        return self.compute_K(self.L)\n",
    "    def step(self,r):\n",
    "        tmp_eig = np.zeros((len(self.eigvalues),len(self.eigvalues)))\n",
    "        indeces = np.argsort(self.eigvalues)[::-1]\n",
    "        best = indeces[:r]\n",
    "        for i in range(self.eigvalues.shape[0]):\n",
    "            if i in best:\n",
    "                tmp_eig[i,i] = 1\n",
    "            else:\n",
    "                tmp_eig[i,i] = 0\n",
    "        L_hat = (self.eigvectors.dot(tmp_eig)).dot(self.eigvectors.T)\n",
    "        self.K = self.compute_K(L_hat)\n",
    "        return self.K\n",
    "    def linear_step(self,r):\n",
    "        tmp_eig = np.diag(self.eigvalues)\n",
    "        for i,e in enumerate(self.eigvalues):\n",
    "            if e < r:\n",
    "                tmp_eig[i,i] = 0\n",
    "        L_hat = (self.eigvectors.dot(tmp_eig)).dot(self.eigvectors.T)\n",
    "        self.K = self.compute_K(L_hat)\n",
    "        return self.K\n",
    "    def polynomial(self,t):\n",
    "        tmp_eig = np.diag(np.power(self.eigvalues,t))\n",
    "        L_hat = (self.eigvectors.dot(tmp_eig)).dot(self.eigvectors.T)\n",
    "        self.K = self.compute_K(L_hat)\n",
    "        return self.K\n",
    "    def poly_step(self,parameter_list):\n",
    "        r = parameter_list[0]\n",
    "        p = parameter_list[1]\n",
    "        q = parameter_list[2]\n",
    "        \n",
    "        tmp_eig = np.zeros((len(self.eigvalues),len(self.eigvalues)))\n",
    "        \n",
    "        indeces = np.argsort(self.eigvalues)[::-1]\n",
    "        #print(self.eigvalues[indeces])\n",
    "        best = indeces[:r]\n",
    "        for i,e in enumerate(self.eigvalues):\n",
    "            if i in best:\n",
    "                tmp_eig[i,i] = np.power(e,p)\n",
    "            else:\n",
    "                tmp_eig[i,i] = np.power(e,q)\n",
    "        L_hat = (self.eigvectors.dot(tmp_eig)).dot(self.eigvectors.T)\n",
    "        self.K = self.compute_K(L_hat)\n",
    "        return self.K\n",
    "    \n",
    "    def distance(self,X1,X2):\n",
    "            gram_matrix = np.zeros((X1.shape[0], X2.shape[0]))\n",
    "            index2list = np.zeros((X2.shape[0]),dtype=int)\n",
    "            for j, x2 in enumerate(X2):\n",
    "                index2list[j] = self.dict[x2.tobytes()]\n",
    "            for i, x1 in enumerate(X1):\n",
    "                ind1 = self.dict[x1.tobytes()]\n",
    "                #print('in sample:',i)\n",
    "                #print(np.ndarray.tobytes())\n",
    "                #print('in the kernel',ind1)\n",
    "                gram_matrix[i, :] = self.K[ind1,index2list]\n",
    "            #print(gram_matrix.shape)\n",
    "            return gram_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USPS_results replication\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "from tsvm import TSVM\n",
    "import pickle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "def k_th_largest_eig(eig,k):\n",
    "    arr = eig.copy()\n",
    "    arr.sort() \n",
    "    return arr[-k]\n",
    "\n",
    "\n",
    "with open ('20news_databases', 'rb') as fp:\n",
    "    news_file = pickle.load(fp) \n",
    "\n",
    "labeled = news_file[0]\n",
    "unlabeled = news_file[1]\n",
    "df_test = news_file[2]\n",
    "\n",
    "df_train = pd.concat((labeled,unlabeled))\n",
    "\n",
    "\n",
    "def get_mean_and_std(method='svm'):\n",
    "    sigma=sig\n",
    "    #accuracy = np.zeros(50)\n",
    "    gam = 1/(2*sigma**2)\n",
    "    \n",
    "    accuracy=np.zeros(100)\n",
    "    for i in range(100):\n",
    "        \n",
    "        if(method=='cluster_kernel'): #cluster kernel\n",
    "            trn = df_train.iloc[:,:-1].to_numpy()\n",
    "            #print(trn)\n",
    "            tes = df_test.iloc[:,:-1].to_numpy()\n",
    "            data = np.concatenate((trn,tes),axis=0)\n",
    "            #print('data dimensions', data.shape)\n",
    "            lin_ker = extension_cluster_kernel(data,'linear')\n",
    "            eig = lin_ker.eigvalues\n",
    "            #print('eig:',eig)\n",
    "            #print('eig length:',eig.shape)\n",
    "            cut_off = k_th_largest_eig(eig,10)\n",
    "            #print('cut_off:',cut_off)\n",
    "            #lin_ker.poly_step([cut_off,1/2,2])\n",
    "            #lin_ker.polynomial(5)\n",
    "            lin_ker.poly_step([10,1/2,2])\n",
    "            labeled_w = df_train.loc[df_train['Labels']==-1].sample(8,random_state=i)\n",
    "            labeled_m = df_train.loc[df_train['Labels']==1].sample(8,random_state=i)\n",
    "            labeled = pd.concat((labeled_w,labeled_m))\n",
    "            unlabeled = df_train.drop(labeled.index)\n",
    "            \n",
    "            print('labeled size',labeled.loc[labeled['Labels']==1].shape)\n",
    "            #print('unlabeled size',unlabeled.shape)\n",
    "            \n",
    "            targets = labeled.iloc[:,-1].to_numpy()\n",
    "            inputs =  labeled.iloc[:,:-1].to_numpy()\n",
    "            unlabeled_targets=unlabeled.iloc[:,-1].to_numpy()\n",
    "            unlabeled_inputs =unlabeled.iloc[:,:-1].to_numpy()\n",
    "            test_inputs = df_test.iloc[:,:-1].to_numpy()\n",
    "            test_targets= df_test.iloc[:,-1].to_numpy()\n",
    "\n",
    "\n",
    "            clf = svm.SVC(kernel=lin_ker.distance, C=100,class_weight='balanced')\n",
    "            #print('number of +1:',targets[targets==1].shape)\n",
    "            #print('number of -1:',targets[targets==-1].shape)\n",
    "            #print('inputs size:',inputs.shape)\n",
    "            clf.fit(inputs,targets)\n",
    "            #print('test:',test_inputs.shape)\n",
    "            accuracy[i] = clf.score(test_inputs,test_targets)\n",
    "            print('accuracy at iteration:',accuracy[i]) \n",
    "        elif(method=='svm'): #svm\n",
    "            \n",
    "            \n",
    "            labeled_w = df_train.loc[df_train['Labels']==-1].sample(8,random_state=i)\n",
    "            labeled_m = df_train.loc[df_train['Labels']==1].sample(8,random_state=i)\n",
    "            labeled = pd.concat((labeled_w,labeled_m))\n",
    "            unlabeled = df_train.drop(labeled.index)\n",
    "            \n",
    "            \n",
    "            targets = labeled.iloc[:,-1].to_numpy()\n",
    "            inputs =  labeled.iloc[:,:-1].to_numpy()\n",
    "            unlabeled_targets=unlabeled.iloc[:,-1].to_numpy()\n",
    "            unlabeled_inputs =unlabeled.iloc[:,:-1].to_numpy()\n",
    "            test_inputs = df_test.iloc[:,:-1].to_numpy()\n",
    "            test_targets= df_test.iloc[:,-1].to_numpy()\n",
    "            \n",
    "            \n",
    "            \n",
    "            #print(inputs_scaled.std(axis=0))\n",
    "            #pca = PCA(n_components = 0.95, svd_solver='full')\n",
    "            #pca.fit(inputs)\n",
    "            #transformed_inputs = pca.transform(inputs)\n",
    "            #transformed_test_inputs = pca.transform(test_inputs)\n",
    "            clf = svm.SVC(kernel='rbf', C=100,gamma=gam,class_weight='balanced')\n",
    "            clf.fit(inputs, targets)\n",
    "            accuracy[i] = clf.score(test_inputs,test_targets)\n",
    "            print('accuracy at iteration:',accuracy[i])\n",
    "            '''print('sigma:', sigma)\n",
    "            print(accuracy)\n",
    "            print('mean:', np.mean(accuracy))\n",
    "            print('std:', np.std(accuracy))'''\n",
    "        elif(method=='tsvm'):#tsvm\n",
    "\n",
    "            #for each i, use partition[i] as train, and the rest as test\n",
    "            \n",
    "            labeled_w = df_train.loc[df_train['Labels']==-1].sample(8,random_state=i)\n",
    "            labeled_m = df_train.loc[df_train['Labels']==1].sample(8,random_state=i)\n",
    "            labeled = pd.concat((labeled_w,labeled_m))\n",
    "            unlabeled = df_train.drop(labeled.index)\n",
    "            \n",
    "            \n",
    "            targets = labeled.iloc[:,-1].to_numpy()\n",
    "            inputs =  labeled.iloc[:,:-1].to_numpy()\n",
    "            unlabeled_targets=unlabeled.iloc[:,-1].to_numpy()\n",
    "            unlabeled_inputs =unlabeled.iloc[:,:-1].to_numpy()\n",
    "            test_inputs = df_test.iloc[:,:-1].to_numpy()\n",
    "            test_targets= df_test.iloc[:,-1].to_numpy()\n",
    "            clf = TSVM()\n",
    "            C = 100\n",
    "            clf.initial('rbf',gam,C,1.5,8)\n",
    "            clf.train(inputs,targets,unlabeled_inputs)\n",
    "            test_predict = clf.predict(test_inputs)\n",
    "            accuracy[i] = test_predict[test_predict==test_targets].size/test_predict.size\n",
    "            print(accuracy[i])\n",
    "            #clf = svm.SVC(kernel='rbf', C=10,gamma=gam,class_weight='balanced')\n",
    "            #clf.fit(inputs, targets)\n",
    "            #accuracy[i] = clf.score(test_inputs,test_targets)\n",
    "            '''print(accuracy)\n",
    "            print('mean:', np.mean(accuracy))\n",
    "            print('std:', np.std(accuracy))'''\n",
    "        else:#random walk\n",
    "            print('random walk initiated')\n",
    "            targets = labeled.iloc[:,-1].to_numpy()\n",
    "            inputs =  labeled.iloc[:,:-1].to_numpy()\n",
    "            unlabeled_targets=unlabeled.iloc[:,-1].to_numpy()\n",
    "            unlabeled_inputs =unlabeled.iloc[:,:-1].to_numpy()\n",
    "            test_inputs = df_test.iloc[:,:-1].to_numpy()\n",
    "            test_targets= df_test.iloc[:,-1].to_numpy()\n",
    "            unl_total = np.concatenate((unlabeled_inputs,test_inputs))\n",
    "\n",
    "            rw = random_walk(inputs,targets,unl_total,gam,10,8)\n",
    "            res = rw.results\n",
    "            #print(res)\n",
    "            print(res.shape)\n",
    "            #test_predict = clf.predict(test_inputs)\n",
    "            #accuracy[i] = \n",
    "            #print(accuracy[i])\n",
    "            predicted_res = res[inputs.shape[0]+unlabeled_inputs.shape[0]:]\n",
    "            #print(predicted_res.shape)\n",
    "            targ = np.concatenate((unlabeled_targets,test_targets))\n",
    "            #print(targ.shape)\n",
    "            accuracy[i] = test_targets[test_targets==predicted_res].shape[0]/test_targets.shape[0]\n",
    "            print(accuracy[i])\n",
    "    print(accuracy)\n",
    "    print('mean',accuracy.mean())\n",
    "    print('std',accuracy.std())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class random_walk:\n",
    "    def __init__(self,labeledData,labels,unlabeledData,gam=None,k=1,t=2):\n",
    "        data = np.concatenate((labeledData,unlabeledData))\n",
    "        L = labeledData.shape[0]\n",
    "        N = data.shape[0]\n",
    "        labels = (1==labels)*1\n",
    "        self.W = rbf_kernel(data,gamma=gam)\n",
    "        for i in range((self.W).shape[0]):\n",
    "            sort = list(np.argsort(self.W[i]))\n",
    "            sort.remove(i)\n",
    "            for j in sort[k:]:\n",
    "                self.W[i,j]=0\n",
    "                \n",
    "        self.W = np.maximum(self.W,(self.W).transpose())\n",
    "        self.P=np.zeros(((self.W).shape))\n",
    "        sumRowsW = np.sum(self.W,axis=1)\n",
    "        for i in range((self.W).shape[0]):\n",
    "            self.P[i]=self.W[i]/sumRowsW[i]\n",
    "        \n",
    "        self.PT = np.linalg.matrix_power(self.P,t)\n",
    "        \n",
    "        self.labelProbability = np.zeros((N,2))\n",
    "        #Initializing random values\n",
    "        for i in range(N):\n",
    "            number = (0.5 - np.random.rand())*0.4\n",
    "            self.labelProbability[i,0] = 0.5+number\n",
    "            self.labelProbability[i,1]=1-self.labelProbability[i,0]\n",
    "        \n",
    "        self.probability = np.zeros((N,L))\n",
    "        oldloglike = -np.inf\n",
    "        self.loglike = np.zeros(100)\n",
    "        for iter in range(100):\n",
    "            #E Step\n",
    "            for i in range(N):\n",
    "                for j in range(L):\n",
    "                    self.probability[i,j] = self.labelProbability[i,labels[j]]*self.PT[i,j]\n",
    "                    \n",
    "            #M Step\n",
    "            for i in range(N):\n",
    "                self.labelProbability[i,0] = (np.sum((labels==0)*self.probability[i]))/(np.sum(self.probability[i])+sys.float_info.epsilon)\n",
    "                self.labelProbability[i,1] = (np.sum((labels==1)*self.probability[i]))/(np.sum(self.probability[i])+sys.float_info.epsilon)\n",
    "            self.loglike[iter] = np.sum(np.log(np.sum(self.probability,axis=0)))\n",
    "            if np.abs(self.loglike[iter] - oldloglike) < 10**(-4):\n",
    "                break\n",
    "            oldloglike = self.loglike[iter]\n",
    "        \n",
    "        self.posterior = np.matmul((self.labelProbability).transpose(),self.PT)\n",
    "        self.results = ((np.argmax(self.posterior,axis = 0))*2)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8386666666666667\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8053333333333333\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.7986666666666666\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8186666666666667\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.7906666666666666\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8253333333333334\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8253333333333334\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.768\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.7986666666666666\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.824\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8253333333333334\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.832\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8266666666666667\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8306666666666667\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.808\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8026666666666666\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8226666666666667\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8306666666666667\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.7786666666666666\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8173333333333334\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.776\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.816\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.7906666666666666\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8066666666666666\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.7813333333333333\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8133333333333334\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8226666666666667\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.7986666666666666\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.832\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.7493333333333333\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.812\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.7906666666666666\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8173333333333334\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8346666666666667\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.82\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8013333333333333\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.7826666666666666\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8213333333333334\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8066666666666666\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8266666666666667\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.7933333333333333\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8133333333333334\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8413333333333334\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8093333333333333\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8293333333333334\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.812\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8026666666666666\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8066666666666666\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8093333333333333\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8226666666666667\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.828\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.776\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.808\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.824\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.7986666666666666\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.7573333333333333\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.7573333333333333\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.824\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.788\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.7906666666666666\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.808\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8293333333333334\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.7893333333333333\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.808\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8133333333333334\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8173333333333334\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.836\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.7826666666666666\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.7613333333333333\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.7546666666666667\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.792\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8253333333333334\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.7666666666666667\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.7786666666666666\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.82\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8186666666666667\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.804\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.7666666666666667\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.808\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8426666666666667\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.7826666666666666\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8306666666666667\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8186666666666667\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8173333333333334\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8346666666666667\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.816\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.7733333333333333\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.808\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.7973333333333333\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.82\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.7826666666666666\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.832\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.76\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.82\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.78\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.824\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8106666666666666\n",
      "labeled size (8, 7512)\n",
      "accuracy at iteration: 0.8453333333333334\n",
      "[0.83866667 0.80533333 0.79866667 0.81866667 0.79066667 0.82533333\n",
      " 0.82533333 0.768      0.79866667 0.8        0.824      0.82533333\n",
      " 0.8        0.832      0.82666667 0.83066667 0.808      0.80266667\n",
      " 0.82266667 0.83066667 0.77866667 0.81733333 0.776      0.816\n",
      " 0.79066667 0.80666667 0.78133333 0.81333333 0.82266667 0.79866667\n",
      " 0.832      0.74933333 0.812      0.79066667 0.81733333 0.83466667\n",
      " 0.82       0.80133333 0.78266667 0.82133333 0.80666667 0.82666667\n",
      " 0.79333333 0.81333333 0.84133333 0.80933333 0.82933333 0.812\n",
      " 0.80266667 0.80666667 0.80933333 0.82266667 0.828      0.776\n",
      " 0.808      0.824      0.79866667 0.75733333 0.75733333 0.824\n",
      " 0.788      0.79066667 0.808      0.82933333 0.78933333 0.808\n",
      " 0.81333333 0.81733333 0.836      0.78266667 0.76133333 0.75466667\n",
      " 0.792      0.82533333 0.76666667 0.77866667 0.82       0.81866667\n",
      " 0.804      0.76666667 0.808      0.84266667 0.78266667 0.83066667\n",
      " 0.81866667 0.81733333 0.83466667 0.816      0.77333333 0.808\n",
      " 0.79733333 0.82       0.78266667 0.832      0.76       0.82\n",
      " 0.78       0.824      0.81066667 0.84533333]\n",
      "mean 0.8063599999999999\n",
      "std 0.022254172143168525\n"
     ]
    }
   ],
   "source": [
    "get_mean_and_std(method='cluster_kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy at iteration: 0.6666666666666666\n",
      "accuracy at iteration: 0.7093333333333334\n",
      "accuracy at iteration: 0.6533333333333333\n",
      "accuracy at iteration: 0.656\n",
      "accuracy at iteration: 0.6253333333333333\n",
      "accuracy at iteration: 0.6613333333333333\n",
      "accuracy at iteration: 0.656\n",
      "accuracy at iteration: 0.64\n",
      "accuracy at iteration: 0.6266666666666667\n",
      "accuracy at iteration: 0.716\n",
      "accuracy at iteration: 0.6986666666666667\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-9bf33a0a1892>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_mean_and_std\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'svm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-23-de2e61c025d2>\u001b[0m in \u001b[0;36mget_mean_and_std\u001b[1;34m(method)\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rbf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgam\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m             \u001b[0maccuracy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'accuracy at iteration:'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m             '''print('sigma:', sigma)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    355\u001b[0m         \"\"\"\n\u001b[0;32m    356\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    572\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m         \"\"\"\n\u001b[1;32m--> 574\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    575\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_dense_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_dense_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobA_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobB_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msvm_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msvm_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m             \u001b[0mdegree\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m             cache_size=self.cache_size)\n\u001b[0m\u001b[0;32m    347\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_sparse_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "get_mean_and_std(method='svm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def JH_bound(dataTrain,targets,dataTest):\n",
    "    data = np.concatenate((dataTrain,dataTest))\n",
    "    kern = extension_cluster_kernel(data,'linear')\n",
    "    linearEigval = -np.sort(-kern.eigvalues)[:(dataTrain.shape[0])+16]\n",
    "    print(linearEigval)\n",
    "    T = np.zeros((len(linearEigval)))\n",
    "    for i,lamda_cut in enumerate(linearEigval):\n",
    "        kern.poly_step([lamda_cut,1/2,2])\n",
    "        clf = svm.SVC(C=100,kernel=kern.distance)\n",
    "        clf.fit(dataTrain,targets)\n",
    "        #print(clf.dual_coef_)\n",
    "        alphas = np.abs(clf.dual_coef_).reshape(-1)\n",
    "        #alphas = clf.dual_coef_.reshape(-1)\n",
    "        supportV = clf.support_\n",
    "        for j in range(len(alphas)):\n",
    "            T[i] += ((alphas[j]*kern.K[supportV[j],supportV[j]]-1)>0)*1\n",
    "            print(T[i])\n",
    "        T[i] = T[i]/dataTrain.shape[0]\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.08703921 0.08471001 0.07666531 0.06992561 0.06540756\n",
      " 0.06445777 0.06258194 0.0622008  0.06159176 0.06057623 0.05922764\n",
      " 0.05895399 0.05847621 0.05838347 0.05786304 0.05735867 0.05712649\n",
      " 0.05667154 0.05583205 0.05505665 0.05417577 0.05362878 0.05338223\n",
      " 0.05314504 0.05307149 0.05295133 0.05235458 0.05219406 0.05189907\n",
      " 0.05166393 0.05136487]\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n",
      "11.0\n",
      "12.0\n",
      "13.0\n",
      "14.0\n",
      "15.0\n",
      "16.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n",
      "11.0\n",
      "12.0\n",
      "13.0\n",
      "14.0\n",
      "15.0\n",
      "16.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n",
      "11.0\n",
      "12.0\n",
      "13.0\n",
      "13.0\n",
      "14.0\n",
      "15.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n",
      "11.0\n",
      "12.0\n",
      "13.0\n",
      "13.0\n",
      "14.0\n",
      "15.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "4.0\n",
      "5.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "7.0\n",
      "7.0\n",
      "8.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "7.0\n",
      "7.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n",
      "11.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "7.0\n",
      "7.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n",
      "11.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "8.0\n",
      "8.0\n",
      "9.0\n",
      "9.0\n",
      "10.0\n",
      "11.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "7.0\n",
      "7.0\n",
      "8.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "7.0\n",
      "7.0\n",
      "8.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "7.0\n",
      "7.0\n",
      "8.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "7.0\n",
      "7.0\n",
      "8.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "4.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "7.0\n",
      "8.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "4.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "7.0\n",
      "8.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "4.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "7.0\n",
      "8.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "4.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "7.0\n",
      "8.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "4.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "7.0\n",
      "8.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "8.0\n",
      "8.0\n",
      "9.0\n",
      "9.0\n",
      "10.0\n",
      "11.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "8.0\n",
      "8.0\n",
      "9.0\n",
      "9.0\n",
      "10.0\n",
      "11.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "4.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "7.0\n",
      "8.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "8.0\n",
      "9.0\n",
      "9.0\n",
      "10.0\n",
      "11.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n",
      "11.0\n",
      "12.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "6.0\n",
      "7.0\n",
      "7.0\n",
      "8.0\n",
      "9.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "6.0\n",
      "7.0\n",
      "7.0\n",
      "8.0\n",
      "9.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "6.0\n",
      "7.0\n",
      "7.0\n",
      "8.0\n",
      "9.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "6.0\n",
      "7.0\n",
      "7.0\n",
      "8.0\n",
      "8.0\n",
      "1.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "5.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "7.0\n",
      "8.0\n",
      "8.0\n",
      "9.0\n",
      "9.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "7.0\n",
      "8.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "7.0\n",
      "8.0\n",
      "8.0\n",
      "9.0\n",
      "10.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "7.0\n",
      "8.0\n",
      "8.0\n",
      "9.0\n",
      "9.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "3.0\n",
      "4.0\n",
      "4.0\n",
      "4.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "7.0\n",
      "8.0\n",
      "9.0\n",
      "1.0\n",
      "2.0\n",
      "2.0\n",
      "3.0\n",
      "3.0\n",
      "3.0\n",
      "4.0\n",
      "5.0\n",
      "5.0\n",
      "6.0\n",
      "7.0\n",
      "8.0\n",
      "9.0\n",
      "9.0\n",
      "10.0\n",
      "11.0\n",
      "[1.     1.     0.9375 0.9375 0.625  0.6875 0.6875 0.6875 0.625  0.625\n",
      " 0.625  0.625  0.625  0.625  0.625  0.625  0.625  0.6875 0.6875 0.625\n",
      " 0.6875 0.75   0.5625 0.5625 0.5625 0.5    0.5625 0.625  0.625  0.5625\n",
      " 0.5625 0.6875]\n"
     ]
    }
   ],
   "source": [
    "targets = labeled.iloc[:,-1].to_numpy()\n",
    "inputs =  labeled.iloc[:,:-1].to_numpy()\n",
    "unlabeled_targets=unlabeled.iloc[:,-1].to_numpy()\n",
    "unlabeled_inputs =unlabeled.iloc[:,:-1].to_numpy()\n",
    "test_inputs = df_test.iloc[:,:-1].to_numpy()\n",
    "test_targets= df_test.iloc[:,-1].to_numpy()\n",
    "\n",
    "tst = np.concatenate((unlabeled_inputs,test_inputs))\n",
    "s = JH_bound(inputs,targets,tst)\n",
    "\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16701f9a320>]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: [0.636 0.   ]\n",
      "poly_step: [0.636 0.   ]\n",
      "step: [0.636 0.32 ]\n",
      "poly_step: [0.636 0.32 ]\n",
      "1\n",
      "step: [0.73333333 0.        ]\n",
      "poly_step: [0.73333333 0.        ]\n",
      "step: [0.73333333 0.59733333]\n",
      "poly_step: [0.73333333 0.59733333]\n",
      "2\n",
      "step: [0.79466667 0.        ]\n",
      "poly_step: [0.79466667 0.        ]\n",
      "step: [0.79466667 0.672     ]\n",
      "poly_step: [0.79466667 0.672     ]\n",
      "3\n",
      "step: [0.736 0.   ]\n",
      "poly_step: [0.736 0.   ]\n",
      "step: [0.736      0.68933333]\n",
      "poly_step: [0.736      0.68933333]\n",
      "4\n",
      "step: [0.73733333 0.        ]\n",
      "poly_step: [0.73733333 0.        ]\n",
      "step: [0.73733333 0.688     ]\n",
      "poly_step: [0.73733333 0.688     ]\n",
      "5\n",
      "step: [0.73066667 0.        ]\n",
      "poly_step: [0.73066667 0.        ]\n",
      "step: [0.73066667 0.708     ]\n",
      "poly_step: [0.73066667 0.708     ]\n",
      "6\n",
      "step: [0.672 0.   ]\n",
      "poly_step: [0.672 0.   ]\n",
      "step: [0.672 0.672]\n",
      "poly_step: [0.672 0.672]\n",
      "7\n",
      "[[0.52666667 0.552      0.62866667 0.68933333 0.75133333 0.79333333\n",
      "  0.83333333]\n",
      " [0.49266667 0.50533333 0.57733333 0.53466667 0.722      0.69133333\n",
      "  0.864     ]\n",
      " [0.478      0.66533333 0.73333333 0.71266667 0.71266667 0.71933333\n",
      "  0.672     ]\n",
      " [0.478      0.66533333 0.73333333 0.71266667 0.71266667 0.71933333\n",
      "  0.672     ]]\n"
     ]
    }
   ],
   "source": [
    "#time to generate figure_2\n",
    "\n",
    "sizes = [2,4,8,16,32,64,128]\n",
    "\n",
    "accuracy=np.zeros((4,len(sizes)))\n",
    "it=0\n",
    "for s in sizes:\n",
    "\n",
    "    accuracy1=np.zeros(2)\n",
    "    accuracy2=np.zeros(2)\n",
    "    accuracy3=np.zeros(2)\n",
    "    accuracy4=np.zeros(2)\n",
    "    for i in range(2):\n",
    "\n",
    "        trn = df_train.iloc[:,:-1].to_numpy()\n",
    "        tes = df_test.iloc[:,:-1].to_numpy()\n",
    "        data = np.concatenate((trn,tes),axis=0)\n",
    "\n",
    "        lin_ker = extension_cluster_kernel(data,'linear')\n",
    "        eig = lin_ker.eigvalues\n",
    "\n",
    "\n",
    "        labeled_w = df_train.loc[df_train['Labels']==-1].sample(int(s/2),random_state=i)\n",
    "        labeled_m = df_train.loc[df_train['Labels']==1].sample(int(s/2),random_state=i)\n",
    "        labeled = pd.concat((labeled_w,labeled_m))\n",
    "        unlabeled = df_train.drop(labeled.index)\n",
    "\n",
    "\n",
    "        targets = labeled.iloc[:,-1].to_numpy()\n",
    "        inputs =  labeled.iloc[:,:-1].to_numpy()\n",
    "        unlabeled_targets=unlabeled.iloc[:,-1].to_numpy()\n",
    "        unlabeled_inputs =unlabeled.iloc[:,:-1].to_numpy()\n",
    "        test_inputs = df_test.iloc[:,:-1].to_numpy()\n",
    "        test_targets= df_test.iloc[:,-1].to_numpy()\n",
    "\n",
    "\n",
    "        clf = svm.SVC(kernel=lin_ker.distance, C=100,class_weight='balanced')\n",
    "        clf.fit(inputs,targets)\n",
    "        accuracy1[i] = clf.score(test_inputs,test_targets)\n",
    "\n",
    "\n",
    "        #poly \n",
    "\n",
    "        lin_ker = extension_cluster_kernel(data,'polynomial',5)\n",
    "\n",
    "        clf = svm.SVC(kernel=lin_ker.distance, C=100,class_weight='balanced')\n",
    "        clf.fit(inputs,targets)\n",
    "        accuracy2[i] = clf.score(test_inputs,test_targets)\n",
    "\n",
    "\n",
    "        #step \n",
    "        \n",
    "        lin_ker = extension_cluster_kernel(data,'linear')\n",
    "        eig = lin_ker.eigvalues\n",
    "        #cut_off = k_th_largest_eig(eig,s+10)\n",
    "        lin_ker.step(s+10)\n",
    "        #lin_ker.poly_step([cut_off,1/2,2])\n",
    "        \n",
    "        k1 = lin_ker.K\n",
    "        \n",
    "        clf = svm.SVC(kernel=lin_ker.distance, C=100,class_weight='balanced')\n",
    "        clf.fit(inputs,targets)\n",
    "        accuracy3[i] = clf.score(test_inputs,test_targets)\n",
    "        print('step:',accuracy3)\n",
    "        lin_ker = extension_cluster_kernel(data,'linear')\n",
    "        eig = lin_ker.eigvalues\n",
    "        #cut_off = k_th_largest_eig(eig,s+10)\n",
    "        lin_ker.poly_step([s+10,1/2,2])\n",
    "        \n",
    "        k2 = lin_ker.K\n",
    "        \n",
    "        #print('the same?', k1==k2)\n",
    "        \n",
    "        accuracy4[i] = clf.score(test_inputs,test_targets)\n",
    "        print('poly_step:',accuracy4)\n",
    "    \n",
    "    accuracy[0][it] = accuracy1.mean()\n",
    "    accuracy[1][it] = accuracy2.mean()\n",
    "    accuracy[2][it] = accuracy3.mean()\n",
    "    accuracy[3][it] = accuracy4.mean()\n",
    "    it=it+1\n",
    "    print(it)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1ab8cdd6470>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(1-accuracy[0],label='svm')\n",
    "plt.plot(1-accuracy[1],label='polynomial')\n",
    "plt.plot(1-accuracy[2],label='step')\n",
    "plt.plot(1-accuracy[3],label='poly_step')\n",
    "plt.xticks(np.arange(len(sizes)),sizes)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.29003517e-18 1.14317231e-03 1.17630483e-03 1.58292109e-03\n",
      " 3.38321045e-03 6.43343233e-03 6.87460402e-03 8.75143290e-03\n",
      " 1.01881947e-02 1.05930844e-02 1.07378471e-02 1.12457728e-02\n",
      " 1.31371957e-02 1.31931624e-02 1.41345781e-02 1.57030534e-02\n",
      " 1.58372785e-02 1.66091261e-02 1.69747807e-02 1.77596785e-02\n",
      " 1.96941503e-02 2.01342689e-02 2.09871682e-02 2.12808983e-02\n",
      " 2.17158877e-02 2.25559740e-02 2.28265032e-02 2.34286178e-02\n",
      " 2.38537922e-02 2.40610042e-02 2.42372399e-02 2.44154763e-02\n",
      " 2.44723848e-02 2.47219828e-02 2.50680048e-02 2.50720803e-02\n",
      " 2.51413074e-02 2.53671283e-02 2.55076233e-02 2.55710051e-02\n",
      " 2.57196548e-02 2.57931552e-02 2.59139461e-02 2.64497662e-02\n",
      " 2.65015323e-02 2.66305585e-02 2.66608022e-02 2.66634241e-02\n",
      " 2.67121306e-02 2.67601750e-02 2.68688270e-02 2.69283441e-02\n",
      " 2.70093487e-02 2.70271645e-02 2.71166399e-02 2.71478670e-02\n",
      " 2.71912024e-02 2.72368810e-02 2.72943066e-02 2.73421561e-02\n",
      " 2.73854137e-02 2.74946733e-02 2.75416366e-02 2.76311081e-02\n",
      " 2.76865885e-02 2.77646270e-02 2.77820513e-02 2.78865932e-02\n",
      " 2.79104797e-02 2.79669574e-02 2.80376004e-02 2.80718428e-02\n",
      " 2.81009531e-02 2.81265993e-02 2.81716769e-02 2.82239626e-02\n",
      " 2.82471893e-02 2.83106898e-02 2.83389772e-02 2.83578054e-02\n",
      " 2.83874125e-02 2.84454250e-02 2.84866901e-02 2.85152515e-02\n",
      " 2.85528192e-02 2.85919798e-02 2.86122380e-02 2.86498766e-02\n",
      " 2.86901518e-02 2.87020293e-02 2.87266145e-02 2.87691001e-02\n",
      " 2.87953847e-02 2.88264272e-02 2.88367712e-02 2.88576688e-02\n",
      " 2.88836236e-02 2.88911936e-02 2.89394053e-02 2.89472142e-02\n",
      " 2.89691278e-02 2.89716492e-02 2.90029704e-02 2.90178172e-02\n",
      " 2.90262118e-02 2.90583035e-02 2.90718671e-02 2.90936761e-02\n",
      " 2.91040211e-02 2.91387877e-02 2.91515921e-02 2.91716113e-02\n",
      " 2.91823256e-02 2.92019226e-02 2.92149939e-02 2.92221341e-02\n",
      " 2.92386205e-02 2.92491111e-02 2.92770798e-02 2.93053621e-02\n",
      " 2.93132869e-02 2.93294484e-02 2.93328020e-02 2.93698669e-02\n",
      " 2.93820452e-02 2.93930363e-02 2.94104739e-02 2.94358190e-02\n",
      " 2.94465426e-02 2.94608399e-02 2.94684372e-02 2.94915758e-02\n",
      " 2.94998597e-02 2.95067708e-02 2.95339465e-02 2.95438835e-02\n",
      " 2.95559208e-02 2.95647501e-02 2.95812229e-02 2.95987197e-02\n",
      " 2.96162823e-02 2.96283586e-02 2.96621625e-02 2.96656751e-02\n",
      " 2.96811340e-02 2.96913968e-02 2.97080659e-02 2.97185094e-02\n",
      " 2.97301036e-02 2.97365152e-02 2.97446371e-02 2.97576546e-02\n",
      " 2.97726114e-02 2.97969540e-02 2.98007073e-02 2.98193608e-02\n",
      " 2.98357643e-02 2.98449260e-02 2.98599470e-02 2.98729151e-02\n",
      " 2.98804699e-02 2.98875301e-02 2.99127643e-02 2.99213828e-02\n",
      " 2.99293903e-02 2.99460089e-02 2.99576665e-02 2.99669750e-02\n",
      " 2.99797048e-02 2.99839799e-02 2.99888664e-02 3.00179285e-02\n",
      " 3.00265432e-02 3.00335589e-02 3.00471174e-02 3.00651790e-02\n",
      " 3.00728087e-02 3.00969716e-02 3.01068073e-02 3.01177649e-02\n",
      " 3.01230828e-02 3.01581236e-02 3.01597307e-02 3.01731864e-02\n",
      " 3.01859675e-02 3.02013768e-02 3.02081463e-02 3.02232780e-02\n",
      " 3.02453065e-02 3.02564402e-02 3.02641274e-02 3.02741766e-02\n",
      " 3.02979599e-02 3.03125769e-02 3.03202575e-02 3.03217785e-02\n",
      " 3.03293546e-02 3.03452123e-02 3.03511209e-02 3.03671570e-02\n",
      " 3.03829980e-02 3.04018743e-02 3.04131231e-02 3.04192334e-02\n",
      " 3.04484770e-02 3.04614319e-02 3.04687615e-02 3.04728679e-02\n",
      " 3.04910725e-02 3.04981170e-02 3.05105429e-02 3.05142508e-02\n",
      " 3.05247798e-02 3.05411096e-02 3.05521965e-02 3.05775084e-02\n",
      " 3.05884602e-02 3.05934898e-02 3.06121366e-02 3.06206648e-02\n",
      " 3.06334294e-02 3.06405058e-02 3.06611391e-02 3.06775289e-02\n",
      " 3.06853874e-02 3.07027845e-02 3.07123256e-02 3.07174216e-02\n",
      " 3.07333057e-02 3.07392049e-02 3.07476560e-02 3.07637927e-02\n",
      " 3.07671755e-02 3.07805066e-02 3.07890629e-02 3.08047842e-02\n",
      " 3.08131734e-02 3.08295432e-02 3.08445540e-02 3.08505518e-02\n",
      " 3.08667664e-02 3.08769523e-02 3.08819433e-02 3.08975793e-02\n",
      " 3.09011328e-02 3.09120379e-02 3.09364797e-02 3.09413230e-02\n",
      " 3.09519032e-02 3.09620292e-02 3.09833537e-02 3.09948293e-02\n",
      " 3.10130984e-02 3.10146507e-02 3.10182686e-02 3.10349338e-02\n",
      " 3.10484390e-02 3.10581994e-02 3.10699603e-02 3.10782359e-02\n",
      " 3.10892048e-02 3.10938522e-02 3.11077101e-02 3.11183181e-02\n",
      " 3.11315755e-02 3.11400647e-02 3.11503045e-02 3.11590231e-02\n",
      " 3.11716279e-02 3.11897742e-02 3.11931480e-02 3.12084958e-02\n",
      " 3.12168006e-02 3.12292039e-02 3.12331053e-02 3.12562491e-02\n",
      " 3.12582424e-02 3.12666110e-02 3.12737247e-02 3.12816386e-02\n",
      " 3.13024202e-02 3.13100221e-02 3.13207382e-02 3.13355535e-02\n",
      " 3.13496583e-02 3.13569502e-02 3.13730369e-02 3.13798012e-02\n",
      " 3.13909908e-02 3.13947962e-02 3.14074141e-02 3.14141546e-02\n",
      " 3.14181649e-02 3.14269764e-02 3.14468068e-02 3.14667061e-02\n",
      " 3.14839574e-02 3.14899442e-02 3.14984000e-02 3.15071469e-02\n",
      " 3.15253088e-02 3.15361809e-02 3.15524151e-02 3.15532800e-02\n",
      " 3.15655858e-02 3.15675622e-02 3.15920237e-02 3.15940168e-02\n",
      " 3.16054011e-02 3.16241950e-02 3.16365529e-02 3.16417464e-02\n",
      " 3.16578140e-02 3.16754685e-02 3.16765533e-02 3.16812048e-02\n",
      " 3.16894620e-02 3.17004585e-02 3.17085038e-02 3.17284246e-02\n",
      " 3.17311783e-02 3.17476488e-02 3.17607283e-02 3.17701260e-02\n",
      " 3.17755623e-02 3.17888615e-02 3.18036122e-02 3.18204096e-02\n",
      " 3.18236464e-02 3.18348989e-02 3.18462777e-02 3.18553817e-02\n",
      " 3.18563978e-02 3.18845390e-02 3.19035335e-02 3.19112200e-02\n",
      " 3.19225320e-02 3.19264103e-02 3.19401829e-02 3.19525238e-02\n",
      " 3.19569198e-02 3.19677696e-02 3.19815056e-02 3.20044888e-02\n",
      " 3.20126014e-02 3.20182929e-02 3.20268298e-02 3.20429847e-02\n",
      " 3.20672413e-02 3.20707756e-02 3.20831387e-02 3.20887480e-02\n",
      " 3.20990513e-02 3.21211009e-02 3.21271522e-02 3.21475535e-02\n",
      " 3.21502416e-02 3.21591204e-02 3.21644374e-02 3.21704708e-02\n",
      " 3.21814053e-02 3.21962800e-02 3.22078100e-02 3.22181376e-02\n",
      " 3.22242828e-02 3.22340791e-02 3.22388802e-02 3.22728472e-02\n",
      " 3.22767908e-02 3.22834053e-02 3.23053839e-02 3.23130758e-02\n",
      " 3.23279262e-02 3.23424087e-02 3.23475185e-02 3.23602036e-02\n",
      " 3.23665811e-02 3.23735162e-02 3.23947079e-02 3.24017448e-02\n",
      " 3.24060455e-02 3.24135588e-02 3.24382170e-02 3.24474504e-02\n",
      " 3.24631573e-02 3.24760238e-02 3.24798590e-02 3.24999933e-02\n",
      " 3.25048696e-02 3.25137551e-02 3.25269836e-02 3.25452021e-02\n",
      " 3.25532323e-02 3.25600580e-02 3.25651022e-02 3.25917555e-02\n",
      " 3.25975856e-02 3.26139642e-02 3.26271994e-02 3.26349814e-02\n",
      " 3.26436878e-02 3.26580225e-02 3.26775411e-02 3.26786295e-02\n",
      " 3.26942575e-02 3.27015302e-02 3.27214208e-02 3.27352035e-02\n",
      " 3.27501149e-02 3.27577613e-02 3.27706010e-02 3.27840570e-02\n",
      " 3.27919817e-02 3.28049070e-02 3.28212212e-02 3.28300111e-02\n",
      " 3.28448359e-02 3.28522860e-02 3.28602385e-02 3.28782492e-02\n",
      " 3.28843038e-02 3.28966220e-02 3.29013384e-02 3.29205455e-02\n",
      " 3.29397242e-02 3.29631619e-02 3.29708370e-02 3.29874654e-02\n",
      " 3.29999238e-02 3.30063540e-02 3.30178646e-02 3.30322395e-02\n",
      " 3.30462483e-02 3.30556009e-02 3.30629355e-02 3.30907194e-02\n",
      " 3.30988005e-02 3.31086018e-02 3.31114025e-02 3.31231801e-02\n",
      " 3.31380304e-02 3.31508766e-02 3.31553389e-02 3.31752612e-02\n",
      " 3.31831035e-02 3.32022398e-02 3.32093862e-02 3.32455855e-02\n",
      " 3.32536715e-02 3.32625008e-02 3.32725357e-02 3.32841761e-02\n",
      " 3.33012168e-02 3.33040325e-02 3.33086988e-02 3.33274093e-02\n",
      " 3.33405176e-02 3.33638107e-02 3.33696483e-02 3.33793176e-02\n",
      " 3.33862572e-02 3.34054258e-02 3.34060445e-02 3.34369784e-02\n",
      " 3.34569951e-02 3.34727923e-02 3.34811635e-02 3.34834668e-02\n",
      " 3.34982955e-02 3.35215525e-02 3.35300600e-02 3.35403583e-02\n",
      " 3.35515015e-02 3.35660260e-02 3.35799109e-02 3.35977918e-02\n",
      " 3.35992123e-02 3.36281941e-02 3.36457047e-02 3.36639640e-02\n",
      " 3.36688065e-02 3.36866849e-02 3.36911573e-02 3.37121277e-02\n",
      " 3.37238161e-02 3.37379866e-02 3.37467485e-02 3.37624930e-02\n",
      " 3.37773029e-02 3.37783858e-02 3.37963514e-02 3.38189041e-02\n",
      " 3.38302046e-02 3.38551192e-02 3.38661363e-02 3.38788502e-02\n",
      " 3.39030062e-02 3.39100250e-02 3.39205748e-02 3.39322844e-02\n",
      " 3.39406532e-02 3.39645011e-02 3.39746517e-02 3.39909252e-02\n",
      " 3.40219119e-02 3.40227192e-02 3.40319655e-02 3.40399336e-02\n",
      " 3.40868849e-02 3.40978928e-02 3.40989724e-02 3.40998721e-02\n",
      " 3.41226218e-02 3.41412688e-02 3.41578071e-02 3.41749256e-02\n",
      " 3.41859020e-02 3.42159305e-02 3.42235017e-02 3.42329231e-02\n",
      " 3.42487787e-02 3.42634043e-02 3.42701404e-02 3.42818158e-02\n",
      " 3.42969998e-02 3.43079301e-02 3.43183413e-02 3.43318414e-02\n",
      " 3.43544988e-02 3.43729469e-02 3.43760718e-02 3.44036247e-02\n",
      " 3.44241676e-02 3.44302970e-02 3.44657173e-02 3.44659993e-02\n",
      " 3.44882313e-02 3.45113524e-02 3.45158267e-02 3.45428508e-02\n",
      " 3.45449636e-02 3.45558407e-02 3.45777839e-02 3.45898761e-02\n",
      " 3.46046620e-02 3.46212450e-02 3.46487123e-02 3.46555249e-02\n",
      " 3.46673464e-02 3.46810732e-02 3.46911788e-02 3.47223888e-02\n",
      " 3.47252428e-02 3.47361126e-02 3.47533450e-02 3.47766187e-02\n",
      " 3.47987036e-02 3.47993280e-02 3.48128356e-02 3.48328458e-02\n",
      " 3.48426872e-02 3.48496005e-02 3.48853055e-02 3.48999542e-02\n",
      " 3.49066588e-02 3.49354240e-02 3.49570469e-02 3.49650381e-02\n",
      " 3.49733523e-02 3.49932643e-02 3.50024791e-02 3.50219614e-02\n",
      " 3.50371064e-02 3.50561372e-02 3.50683348e-02 3.50965402e-02\n",
      " 3.51002758e-02 3.51092799e-02 3.51299351e-02 3.51501706e-02\n",
      " 3.51540158e-02 3.51825712e-02 3.51857310e-02 3.52067533e-02\n",
      " 3.52248453e-02 3.52499376e-02 3.52639069e-02 3.52764944e-02\n",
      " 3.52814943e-02 3.53003963e-02 3.53337056e-02 3.53389347e-02\n",
      " 3.53495358e-02 3.53510227e-02 3.53794157e-02 3.53948310e-02\n",
      " 3.54106995e-02 3.54399797e-02 3.54620543e-02 3.54763613e-02\n",
      " 3.55108477e-02 3.55198315e-02 3.55288042e-02 3.55440166e-02\n",
      " 3.55544823e-02 3.55649175e-02 3.55851985e-02 3.55974535e-02\n",
      " 3.56167919e-02 3.56540334e-02 3.56893294e-02 3.56942082e-02\n",
      " 3.57152149e-02 3.57315943e-02 3.57403417e-02 3.57466524e-02\n",
      " 3.57691897e-02 3.57789196e-02 3.57851479e-02 3.58016000e-02\n",
      " 3.58300900e-02 3.58329214e-02 3.58549018e-02 3.58831012e-02\n",
      " 3.59172053e-02 3.59415590e-02 3.59497358e-02 3.59603218e-02\n",
      " 3.59840816e-02 3.59997863e-02 3.60094088e-02 3.60284417e-02\n",
      " 3.60431147e-02 3.60801007e-02 3.60904115e-02 3.61014612e-02\n",
      " 3.61161779e-02 3.61526978e-02 3.61580641e-02 3.61736488e-02\n",
      " 3.61932616e-02 3.62081529e-02 3.62249456e-02 3.62421746e-02\n",
      " 3.62539434e-02 3.62834903e-02 3.62927012e-02 3.63202809e-02\n",
      " 3.63641987e-02 3.63757647e-02 3.63859568e-02 3.64116133e-02\n",
      " 3.64381475e-02 3.64579957e-02 3.64897162e-02 3.64995410e-02\n",
      " 3.65379369e-02 3.65582993e-02 3.65683311e-02 3.65926718e-02\n",
      " 3.66104929e-02 3.66178971e-02 3.66253995e-02 3.66641411e-02\n",
      " 3.66748606e-02 3.67013131e-02 3.67176348e-02 3.67703814e-02\n",
      " 3.67749728e-02 3.68009266e-02 3.68169111e-02 3.68413752e-02\n",
      " 3.68740592e-02 3.68846347e-02 3.69034824e-02 3.69245874e-02\n",
      " 3.69518982e-02 3.69615265e-02 3.69889476e-02 3.70466715e-02\n",
      " 3.70556937e-02 3.70709464e-02 3.70937431e-02 3.71083045e-02\n",
      " 3.71499317e-02 3.71673263e-02 3.71725988e-02 3.71938854e-02\n",
      " 3.72106999e-02 3.72289108e-02 3.72890522e-02 3.72913822e-02\n",
      " 3.73254176e-02 3.73477105e-02 3.73943712e-02 3.74031691e-02\n",
      " 3.74141428e-02 3.74391820e-02 3.74644510e-02 3.74862935e-02\n",
      " 3.75222396e-02 3.75456898e-02 3.75593326e-02 3.75744308e-02\n",
      " 3.76128102e-02 3.76385579e-02 3.76844202e-02 3.76952169e-02\n",
      " 3.77358919e-02 3.77613108e-02 3.77721847e-02 3.77938752e-02\n",
      " 3.78276434e-02 3.78714318e-02 3.79083008e-02 3.79193406e-02\n",
      " 3.79916878e-02 3.80170359e-02 3.80423449e-02 3.80559682e-02\n",
      " 3.80879050e-02 3.81215289e-02 3.81679783e-02 3.81959676e-02\n",
      " 3.82456579e-02 3.82587064e-02 3.83345453e-02 3.83566592e-02\n",
      " 3.83744230e-02 3.84214003e-02 3.84380789e-02 3.84467171e-02\n",
      " 3.85038323e-02 3.85436705e-02 3.85899905e-02 3.86305644e-02\n",
      " 3.86678606e-02 3.86746408e-02 3.87400247e-02 3.87742241e-02\n",
      " 3.88154035e-02 3.88444241e-02 3.88818234e-02 3.89472766e-02\n",
      " 3.89803701e-02 3.90463579e-02 3.90794732e-02 3.90856013e-02\n",
      " 3.91577827e-02 3.92025237e-02 3.92379771e-02 3.92875733e-02\n",
      " 3.93432317e-02 3.94007200e-02 3.94699183e-02 3.95158502e-02\n",
      " 3.95509604e-02 3.96343939e-02 3.96462499e-02 3.97155368e-02\n",
      " 3.97364265e-02 3.98082730e-02 3.98442736e-02 3.99126332e-02\n",
      " 3.99156915e-02 3.99550520e-02 3.99875374e-02 4.00509973e-02\n",
      " 4.01359660e-02 4.02318434e-02 4.02757835e-02 4.03422557e-02\n",
      " 4.03833069e-02 4.04273106e-02 4.04567539e-02 4.05008300e-02\n",
      " 4.05435723e-02 4.07004902e-02 4.07155566e-02 4.08497168e-02\n",
      " 4.08739757e-02 4.09042668e-02 4.10797075e-02 4.12172677e-02\n",
      " 4.12330012e-02 4.12856160e-02 4.13661973e-02 4.14120137e-02\n",
      " 4.14986565e-02 4.15680784e-02 4.16131731e-02 4.17580141e-02\n",
      " 4.18440487e-02 4.20167883e-02 4.20819042e-02 4.21088204e-02\n",
      " 4.22353384e-02 4.23302442e-02 4.23803009e-02 4.24555440e-02\n",
      " 4.25070231e-02 4.26275008e-02 4.26868402e-02 4.28174858e-02\n",
      " 4.29640952e-02 4.30911251e-02 4.32273349e-02 4.32580956e-02\n",
      " 4.33714773e-02 4.34798732e-02 4.36219211e-02 4.37584021e-02\n",
      " 4.39288305e-02 4.39843929e-02 4.42596625e-02 4.43624909e-02\n",
      " 4.44958191e-02 4.45728216e-02 4.46954515e-02 4.49077567e-02\n",
      " 4.50089969e-02 4.52109825e-02 4.53493376e-02 4.54137782e-02\n",
      " 4.56974007e-02 4.58311671e-02 4.59841401e-02 4.62330825e-02\n",
      " 4.64428994e-02 4.64753724e-02 4.69839876e-02 4.71028595e-02\n",
      " 4.71797831e-02 4.74361519e-02 4.76323715e-02 4.80352199e-02\n",
      " 4.81807102e-02 4.83523597e-02 4.85712742e-02 4.88475205e-02\n",
      " 4.95306536e-02 4.98969035e-02 5.00238368e-02 5.02138906e-02\n",
      " 5.08296061e-02 5.09845827e-02 5.13648682e-02 5.16639256e-02\n",
      " 5.18990738e-02 5.21940605e-02 5.23545803e-02 5.29513344e-02\n",
      " 5.30714932e-02 5.31450434e-02 5.33822286e-02 5.36287808e-02\n",
      " 5.41757723e-02 5.50566542e-02 5.58320460e-02 5.66715380e-02\n",
      " 5.71264935e-02 5.73586653e-02 5.78630438e-02 5.83834676e-02\n",
      " 5.84762083e-02 5.89539898e-02 5.92276438e-02 6.05762276e-02\n",
      " 6.15917553e-02 6.22007959e-02 6.25819366e-02 6.44577735e-02\n",
      " 6.54075648e-02 6.99256077e-02 7.66653051e-02 8.47100134e-02\n",
      " 8.70392141e-02 1.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "trn = df_train.iloc[:,:-1].to_numpy()\n",
    "tes = df_test.iloc[:,:-1].to_numpy()\n",
    "data = np.concatenate((trn,tes),axis=0)\n",
    "\n",
    "lin_ker = extension_cluster_kernel(data,'linear')\n",
    "eig = lin_ker.eigvalues\n",
    "print(eig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
